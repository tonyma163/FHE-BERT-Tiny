{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/3t/qv8zrd4d5t12dqxjq4rxf56r0000gn/T/ipykernel_3095/732941677.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  trained = torch.load('./notebooks/SST-2-BERT-tiny.bin', map_location=torch.device(device))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ============================\n",
    "# Step 1: Load the Model and Dataset\n",
    "# ============================\n",
    "\n",
    "device = \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "\n",
    "# Load fine-tuned model\n",
    "trained = torch.load('./notebooks/SST-2-BERT-tiny.bin', map_location=torch.device(device))\n",
    "trained.pop('bert.embeddings.position_ids', None)  # Remove unexpected keys if any\n",
    "model.load_state_dict(trained, strict=True)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load the SST-2 training dataset\n",
    "train_dataset = load_dataset(\"stanfordnlp/sst2\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"stanfordnlp/sst2\", split=\"validation\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['sentence'], truncation=True, padding='max_length', max_length=55)\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "train_dataloader = DataLoader(tokenized_train_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67349, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hide new secretions from the parental units '"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67349"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "mean_distribution = []\n",
    "var_distribution = []\n",
    "\n",
    "for sentence in train_dataset['sentence']:\n",
    "    text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    xx = model.embeddings(tokens_tensor, segments_tensors)\n",
    "    xx = model.encoder.layer[0].attention.self(xx)[0].double()\n",
    "    \n",
    "    w_output_dense = model.encoder.layer[0].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.encoder.layer[0].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    xx = torch.matmul(xx, w_output_dense) + b_output_dense\n",
    "    xx = xx + model.embeddings(tokens_tensor, segments_tensors)\n",
    "\n",
    "    means = []\n",
    "    variances = []\n",
    "\n",
    "    for i in range(55):\n",
    "        xi = xx.squeeze()[i]\n",
    "        means.append(torch.mean(xi.squeeze()).item())\n",
    "        variances.append(1 / math.sqrt(torch.var(xi.squeeze()).item()))\n",
    "    \n",
    "    mean_distribution.append(np.array(means))\n",
    "    var_distribution.append(np.array(variances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertSdpaSelfAttention(\n",
       "  (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.encoder.layer[0].attention.self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[192], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m fin2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(fin, w_output_dense) \u001b[38;5;241m+\u001b[39m b_output_dense\n\u001b[1;32m     27\u001b[0m fin2_backup \u001b[38;5;241m=\u001b[39m fin2\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m---> 28\u001b[0m fin2_backup \u001b[38;5;241m=\u001b[39m fin2_backup \u001b[38;5;241m+\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m mean_0_0 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m var_0_0 \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    216\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n\u001b[1;32m    217\u001b[0m     embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 218\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/torch/nn/modules/normalization.py:202\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/torch/nn/functional.py:2576\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2574\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2575\u001b[0m     )\n\u001b[0;32m-> 2576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "mean_distribution = []\n",
    "var_distribution = []\n",
    "\n",
    "for sentence in train_dataset['sentence']:\n",
    "    text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    # Embeddings\n",
    "    xx = model.bert.embeddings(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Self-Attention\n",
    "    #xx = model.bert.encoder.layer[0].attention.self(xx)[0].double()\n",
    "    fin = model.bert.encoder.layer[0].attention.self(xx)[0].double()\n",
    "\n",
    "    w_output_dense = model.bert.encoder.layer[0].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[0].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + model.bert.embeddings(tokens_tensor, segments_tensors)\n",
    "\n",
    "    mean_0_0 = []\n",
    "    var_0_0 = []\n",
    "\n",
    "    fin3_whole = []\n",
    "    for i in range(len(fin2_backup.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "        current_mean = torch.mean(fin2.squeeze()).item()\n",
    "        current_var = 1 / math.sqrt(torch.var(fin2.squeeze()).item())\n",
    "\n",
    "        # save mean and variance\n",
    "        mean_0_0.append(current_mean)\n",
    "        var_0_0.append(current_var)\n",
    "\n",
    "        fin3_corr = (fin2.squeeze() - current_mean) * current_var\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.weight.clone().detach().double()\n",
    "        b_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr, w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr)\n",
    "\n",
    "    mean_distribution.append(np.array(mean_0_0))\n",
    "    var_distribution.append(np.array(var_0_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [00:05<00:00, 153.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "mean_distribution_0_0 = []\n",
    "var_distribution_0_0 = []\n",
    "mean_distribution_0_1 = []\n",
    "var_distribution_0_1 = []\n",
    "mean_distribution_1_0 = []\n",
    "var_distribution_1_0 = []\n",
    "mean_distribution_1_1 = []\n",
    "var_distribution_1_1 = []\n",
    "\n",
    "for sentence in tqdm(valid_dataset['sentence']):\n",
    "    text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    # Embeddings\n",
    "    xx = model.bert.embeddings(tokens_tensor, segments_tensors)\n",
    "    original_input_tensor = xx.double()\n",
    "    input_tensor = xx.double()\n",
    "\n",
    "    # Self-Attention\n",
    "    #xx = model.bert.encoder.layer[0].attention.self(xx)[0].double()\n",
    "    fin = model.bert.encoder.layer[0].attention.self(xx)[0].double()\n",
    "\n",
    "    w_output_dense = model.bert.encoder.layer[0].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[0].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + original_input_tensor\n",
    "\n",
    "    mean_0_0 = []\n",
    "    var_0_0 = []\n",
    "\n",
    "    fin3_whole = []\n",
    "    for i in range(len(original_input_tensor.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "        current_mean = torch.mean(fin2.squeeze()).item()\n",
    "        current_var = 1 / math.sqrt(torch.var(fin2.squeeze()).item())\n",
    "\n",
    "        # save mean and variance\n",
    "        mean_0_0.append(current_mean)\n",
    "        var_0_0.append(current_var)\n",
    "\n",
    "        fin3_corr = (fin2.squeeze() - current_mean) * current_var\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr)\n",
    "\n",
    "    mean_distribution_0_0.append(np.array(mean_0_0))\n",
    "    var_distribution_0_0.append(np.array(var_0_0))\n",
    "\n",
    "    fin3_whole = torch.cat(tuple(fin3_whole), 0).unsqueeze(0)\n",
    "    fin_4 = torch.matmul(fin3_whole, model.bert.encoder.layer[0].intermediate.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[0].intermediate.dense.bias\n",
    "\n",
    "    fin_5 = torch.nn.functional.gelu(fin_4)\n",
    "    fin_6 = torch.matmul(fin_5, model.bert.encoder.layer[0].output.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[0].output.dense.bias\n",
    "    fin_6 = fin_6 + fin3_whole\n",
    "\n",
    "    mean_0_1 = []\n",
    "    var_0_1 = []\n",
    "\n",
    "    fin7_whole = []\n",
    "    for i in range(len(input_tensor.squeeze())):\n",
    "        fin7 = fin_6.squeeze()[i]\n",
    "\n",
    "        current_mean = torch.mean(fin7.squeeze()).item()\n",
    "        current_var = 1 / math.sqrt(torch.var(fin7.squeeze()).item())\n",
    "\n",
    "        # save mean and variance\n",
    "        mean_0_1.append(current_mean)\n",
    "        var_0_1.append(current_var)\n",
    "\n",
    "        fin7_corr = (fin7.squeeze() - current_mean) * current_var\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[0].output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[0].output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin7_corr = fin7_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin7_whole.append(fin7_corr)\n",
    "        \n",
    "\n",
    "    mean_distribution_0_1.append(np.array(mean_0_1))\n",
    "    var_distribution_0_1.append(np.array(var_0_1))\n",
    "\n",
    "    fin7_whole = torch.cat(tuple(fin7_whole), 0).unsqueeze(0)\n",
    "\n",
    "    original_input_tensor = fin7_whole\n",
    "\n",
    "    fin = model.bert.encoder.layer[1].attention.self(fin7_whole)[0].double()\n",
    "\n",
    "    w_output_dense = model.bert.encoder.layer[1].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[1].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + original_input_tensor\n",
    "\n",
    "    mean_1_0 = []\n",
    "    var_1_0 = []\n",
    "\n",
    "    fin3_whole = []\n",
    "    for i in range(len(original_input_tensor.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "        current_mean = torch.mean(fin2.squeeze()).item()\n",
    "        current_var = 1 / math.sqrt(torch.var(fin2.squeeze()).item())\n",
    "\n",
    "        mean_1_0.append(current_mean)\n",
    "        var_1_0.append(current_var)\n",
    "\n",
    "        fin3_corr = (fin2.squeeze() - current_mean) * current_var\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[1].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[1].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr)\n",
    "\n",
    "    mean_distribution_1_0.append(np.array(mean_1_0))\n",
    "    var_distribution_1_0.append(np.array(var_1_0))\n",
    "\n",
    "    fin3_whole = torch.cat(tuple(fin3_whole), 0).unsqueeze(0)\n",
    "    fin_4 = torch.matmul(fin3_whole, model.bert.encoder.layer[1].intermediate.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[1].intermediate.dense.bias\n",
    "\n",
    "    fin_5 = torch.nn.functional.gelu(fin_4)\n",
    "    fin_6 = torch.matmul(fin_5, model.bert.encoder.layer[1].output.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[1].output.dense.bias\n",
    "    fin_6 = fin_6 + fin3_whole\n",
    "    \n",
    "    mean_1_1 = []\n",
    "    var_1_1 = []\n",
    "\n",
    "    fin7_whole = []\n",
    "    for i in range(len(input_tensor.squeeze())):\n",
    "        fin7 = fin_6.squeeze()[i]\n",
    "\n",
    "        current_mean = torch.mean(fin7.squeeze()).item()\n",
    "        current_var = 1 / math.sqrt(torch.var(fin7.squeeze()).item())\n",
    "\n",
    "        mean_1_1.append(current_mean)\n",
    "        var_1_1.append(current_var)\n",
    "\n",
    "        fin7_corr = (fin7.squeeze() - current_mean) * current_var\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[1].output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[1].output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin7_corr = fin7_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin7_whole.append(fin7_corr.unsqueeze(0))\n",
    "\n",
    "    mean_distribution_1_1.append(np.array(mean_1_1))\n",
    "    var_distribution_1_1.append(np.array(var_1_1))\n",
    "\n",
    "    fin7_whole = torch.cat(tuple(fin7_whole), 0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17616"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_distribution[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03460026379046557\n"
     ]
    }
   ],
   "source": [
    "# find each token position mean of mean_distribution\n",
    "total_mean_0_0 = []\n",
    "sum = 0;\n",
    "for i in range(len(mean_distribution)):\n",
    "    sum += np.mean(mean_distribution[i][0])\n",
    "\n",
    "print(sum/len(mean_distribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def precision(correct, approx):\n",
    "    if isinstance(approx, list):\n",
    "        approx = np.array(approx)\n",
    "    absolute = np.sum(np.abs(correct - approx)) / len(correct)\n",
    "    relative = absolute / (np.sum(np.abs(correct)) / len(correct))\n",
    "    return 1 - relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_mean_0_0 = np.loadtxt(\"./weights-sst2/layer0_selfoutput_mean.txt\")\n",
    "real_mean_0_1 = np.loadtxt(\"./weights-sst2/layer0_output_mean.txt\")\n",
    "real_mean_1_0 = np.loadtxt(\"./weights-sst2/layer1_selfoutput_mean.txt\")\n",
    "real_mean_1_1 = np.loadtxt(\"./weights-sst2/layer1_output_mean.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 0 mean: -0.09405281883323419\n",
      "Position 1 mean: 0.03478227947344718\n",
      "Position 2 mean: 0.03955231243180054\n",
      "Position 3 mean: 0.04100700399849076\n",
      "Position 4 mean: 0.044454166752222586\n",
      "Position 5 mean: 0.04935611358633444\n",
      "Position 6 mean: 0.04950300960598524\n",
      "Position 7 mean: 0.04804027485051588\n",
      "Position 8 mean: 0.04926838412151814\n",
      "Position 9 mean: 0.04887909554475611\n",
      "Position 10 mean: 0.047896674133086015\n",
      "Position 11 mean: 0.051112126845139064\n",
      "Position 12 mean: 0.051096849669458266\n",
      "Position 13 mean: 0.04947306479410882\n",
      "Position 14 mean: 0.048564172826746514\n",
      "Position 15 mean: 0.04752711313564156\n",
      "Position 16 mean: 0.045470358193168754\n",
      "Position 17 mean: 0.045431951713177085\n",
      "Position 18 mean: 0.04673999271555818\n",
      "Position 19 mean: 0.05176381057983726\n",
      "Position 20 mean: 0.049251440846861526\n",
      "Position 21 mean: 0.04900623448904927\n",
      "Position 22 mean: 0.0484905850906113\n",
      "Position 23 mean: 0.049154945098170706\n",
      "Position 24 mean: 0.05004565285994915\n",
      "Position 25 mean: 0.051870537056842095\n",
      "Position 26 mean: 0.05070921270705373\n",
      "Position 27 mean: 0.05586117397064568\n",
      "Position 28 mean: 0.055329576981597996\n",
      "Position 29 mean: 0.04996879213132646\n",
      "Position 30 mean: 0.04789721393476637\n",
      "Position 31 mean: 0.047967660617568644\n",
      "Position 32 mean: 0.042949010386108065\n",
      "Position 33 mean: 0.042962157452559525\n",
      "Position 34 mean: 0.046578896850729364\n",
      "Position 35 mean: 0.04796029559984834\n",
      "Position 36 mean: 0.04771188125278727\n",
      "Position 37 mean: 0.045366759099333874\n",
      "Position 38 mean: 0.04379723147791358\n",
      "Position 39 mean: 0.03919187493003861\n",
      "Position 40 mean: 0.04391273473616758\n",
      "Position 41 mean: 0.04372079296669001\n",
      "Position 42 mean: 0.045163782690360275\n",
      "Position 43 mean: 0.043370042250185106\n",
      "Position 44 mean: 0.04564567574173223\n",
      "Position 45 mean: 0.039246174459692924\n",
      "Position 46 mean: 0.037847916968611214\n",
      "Position 47 mean: 0.04125709156939697\n",
      "Position 48 mean: 0.04427488504649129\n",
      "Position 49 mean: 0.0503016428570735\n",
      "Position 50 mean: 0.0435139734633247\n",
      "Position 51 mean: 0.046627573961098685\n",
      "Position 52 mean: 0.044418093136267545\n",
      "Position 53 mean: 0.0373974671575013\n",
      "Position 54 mean: 0.03934322873434323\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean for each token position across all samples\n",
    "max_length = max(len(sample) for sample in mean_distribution_0_1)\n",
    "total_means = np.zeros(max_length)\n",
    "counts = np.zeros(max_length)\n",
    "\n",
    "for sample in mean_distribution_0_1:\n",
    "    for i, value in enumerate(sample):\n",
    "        total_means[i] += np.mean(value)\n",
    "        counts[i] += 1\n",
    "\n",
    "# Calculate average mean for each position\n",
    "average_means = total_means / counts\n",
    "\n",
    "# Print the results\n",
    "for i, mean in enumerate(average_means):\n",
    "    print(f\"Position {i} mean: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9999998748343766\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate mean for each token position across all samples\n",
    "max_length = max(len(sample) for sample in mean_distribution_0_0)\n",
    "total_means = np.zeros(128)  # Initialize with 128 positions\n",
    "counts = np.zeros(128)  # Initialize with 128 positions\n",
    "\n",
    "for sample in mean_distribution_0_0:\n",
    "    for i, value in enumerate(sample):\n",
    "        if i < 128:  # Only consider up to 128 positions\n",
    "            total_means[i] += np.mean(value)\n",
    "            counts[i] += 1\n",
    "\n",
    "# Calculate average mean for each position\n",
    "average_means = np.zeros(128)\n",
    "for i in range(128):\n",
    "    if counts[i] > 0:\n",
    "        average_means[i] = total_means[i] / counts[i]\n",
    "    # If count is 0, the average_means[i] remains 0\n",
    "\n",
    "# Print the results\n",
    "\"\"\"for i, mean in enumerate(average_means):\n",
    "    print(f\"Position {i} mean: {mean}\")\"\"\"\n",
    "\n",
    "# Calculate precision\n",
    "precision_value = precision(real_mean_0_0, average_means)\n",
    "print(f\"Precision: {precision_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
