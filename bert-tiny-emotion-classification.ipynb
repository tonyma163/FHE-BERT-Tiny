{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee27cd04-08f7-4ed3-98cf-67a6cc9633e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Valid the mentioned accuracy on huggingface repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b87d2060-a46a-4bfc-a52c-08aac2615d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14992236-c3cc-4000-b480-99858607d1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonyma/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/tonyma/code/FHE-BERT-Tiny/env/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gokuls/BERT-tiny-emotion-intent\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gokuls/BERT-tiny-emotion-intent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db495e7-ee8b-48b0-a2f1-32ae6602ad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-1): 2 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c04cbe-4bed-4334-adac-914303b0ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "valid_dataset = load_dataset(\"dair-ai/emotion\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a9afdc-675f-4beb-8506-b76e2fd7231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2000\n",
      "})\n",
      "{'text': 'im feeling quite sad and sorry for myself but ill snap out of it soon', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "print(valid_dataset)\n",
    "print(valid_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c61133-606a-4fc9-bdc3-0ccf4209270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], truncation=True, padding='max_length', max_length=128)\n",
    "tokenized_valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_valid_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Create a dataloader\n",
    "valid_dataloader = DataLoader(tokenized_valid_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06727e6-065d-40ce-9f10-495020c7b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "import torch\n",
    "\n",
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Store predictions and true labels\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in valid_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        logits = logits.detach().cpu()\n",
    "        label_ids = labels.to('cpu')\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        predictions.extend(torch.argmax(logits, dim=1).numpy())\n",
    "        true_labels.extend(label_ids.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c0ae424-4356-47d9-a7aa-8edd723a4011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9100\n",
      "Precision: 0.9117\n",
      "Recall:    0.9100\n",
      "F1-Score:  0.9102\n",
      "Confusion Matrix:\n",
      "[[516  12   3  10   7   2]\n",
      " [ 12 655  24   2   3   8]\n",
      " [  1  19 155   3   0   0]\n",
      " [ 13   4   1 253   4   0]\n",
      " [ 16   3   0   7 170  16]\n",
      " [  1   4   1   1   3  71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.92      0.94      0.93       550\n",
      "         joy       0.94      0.93      0.94       704\n",
      "        love       0.84      0.87      0.86       178\n",
      "       anger       0.92      0.92      0.92       275\n",
      "        fear       0.91      0.80      0.85       212\n",
      "    surprise       0.73      0.88      0.80        81\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.88      0.89      0.88      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Generate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Detailed Classification Report\n",
    "report = classification_report(true_labels, predictions, target_names=valid_dataset.features['label'].names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84949e26-5e69-435f-9acf-ebb7229f8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2efd66d4-c5b5-41ec-8e45-debb212ea06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Record the mean & inverse variance of each LayerNorm for further pre-compute LayerNorm computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3901b5b1-4412-41c1-862d-04b88078456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 16000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load train dataset\n",
    "train_dataset = load_dataset(\"dair-ai/emotion\", split=\"train\")\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b10e30f8-9f82-4d86-a15d-150e8933dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Create a dataloader\n",
    "train_dataloader = DataLoader(tokenized_train_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d73b41-cf71-4cc8-9020-5ce43550243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store LayerNorm Inputs\n",
    "layernorm_inputs = {\n",
    "    'layer0_self_output': [],\n",
    "    'layer0_output': [],\n",
    "    'layer1_self_output': [],\n",
    "    'layer1_output': []\n",
    "}\n",
    "\n",
    "# Hook function to capture the inputs from each LayerNorm layer\n",
    "def get_layernorm_input(layer):\n",
    "    def hook(module, input):\n",
    "        layernorm_inputs[layer].append(input[0].detach().cpu())\n",
    "    return hook\n",
    "layer0_self_output_hook = model.bert.encoder.layer[0].attention.output.LayerNorm.register_forward_pre_hook(\n",
    "    get_layernorm_input('layer0_self_output')\n",
    ")\n",
    "layer0_output_hook = model.bert.encoder.layer[0].output.LayerNorm.register_forward_pre_hook(\n",
    "    get_layernorm_input('layer0_output')\n",
    ")\n",
    "layer1_self_output_hook = model.bert.encoder.layer[1].attention.output.LayerNorm.register_forward_pre_hook(\n",
    "    get_layernorm_input('layer1_self_output')\n",
    ")\n",
    "layer1_output_hook = model.bert.encoder.layer[1].output.LayerNorm.register_forward_pre_hook(\n",
    "    get_layernorm_input('layer1_output')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "777dc084-2b40-4186-bde1-74a59f8d46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 69.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Process\n",
    "attention_mask_list = [] # to excludle padding tokens\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        attention_mask_list.append(attention_mask.detach())\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Clean the hooks\n",
    "layer0_self_output_hook.remove()\n",
    "layer0_output_hook.remove()\n",
    "layer1_self_output_hook.remove()\n",
    "layer1_output_hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "83cb6062-1f08-47ab-845a-d1bf29d6c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import os\n",
    "import numpy as np\n",
    "\n",
    "# to excludle padding tokens\n",
    "all_attention_masks = torch.cat(attention_mask_list, dim=0)\n",
    "all_attention_masks = all_attention_masks.view(-1)\n",
    "\n",
    "# Compute the mean & inverse sqrt variance for each LayerNorm layer\n",
    "for layer, input_list in layernorm_inputs.items():\n",
    "    # concatenate all inputs for the current layer\n",
    "    all_inputs = torch.cat(input_list, dim=0)\n",
    "\n",
    "    # flatten the inputs to merge batch and sequence dimensions\n",
    "    total_samples, seq_length, hidden_size = all_inputs.shape\n",
    "    all_inputs = all_inputs.view(-1, hidden_size)\n",
    "\n",
    "    # exclude padding tokens\n",
    "    valid_indices = all_attention_masks.nonzero(as_tuple=False).squeeze()\n",
    "    valid_inputs = all_inputs[valid_indices]\n",
    "\n",
    "    # Compute mean and variance across all tokens and samples for each feature\n",
    "    mean = valid_inputs.mean(dim=0).double()\n",
    "    var = valid_inputs.var(dim=0, unbiased=False).double()\n",
    "\n",
    "    # Compute the inverse square root of variance + epsilon\n",
    "    epsilon = 1e-12\n",
    "    inv_sqrt_var = 1.0 / torch.sqrt(var + epsilon)\n",
    "    \n",
    "    #print(layer)\n",
    "    ln = None\n",
    "    # Compute vy & normbias\n",
    "    if (layer == \"layer0_self_output\"):\n",
    "        ln = model.bert.encoder.layer[0].attention.output.LayerNorm\n",
    "    elif (layer == \"layer0_output\"):\n",
    "        ln = model.bert.encoder.layer[0].output.LayerNorm\n",
    "    elif (layer == \"layer1_self_output\"):\n",
    "        ln = model.bert.encoder.layer[1].attention.output.LayerNorm\n",
    "    elif (layer == \"layer1_output\"):\n",
    "        ln = model.bert.encoder.layer[1].output.LayerNorm\n",
    "    \n",
    "    gamma = ln.weight.clone().detach().double()\n",
    "    beta = ln.bias.clone().detach().double()\n",
    "    \n",
    "    # Compute vy\n",
    "    vy = (gamma * inv_sqrt_var)\n",
    "    #normbias = beta - (gamma * mean * inv_sqrt_var)\n",
    "    normbias = beta\n",
    "    \n",
    "    #\n",
    "    path = \"./precomputed_layernorm\"\n",
    "    if not (os.path.exists(path)):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    # self_output -> selfoutput\n",
    "    layer = layer.replace('self_output', 'selfoutput')    \n",
    "        \n",
    "    # Save the means & inverse sqrt variance to text files\n",
    "    np.savetxt(f\"./{path}/{layer}_mean.txt\", mean.numpy())\n",
    "    np.savetxt(f\"./{path}/{layer}_inv_sqrt_var.txt\", inv_sqrt_var.numpy())\n",
    "    \n",
    "    # Save the vy & normbias\n",
    "    np.savetxt(f\"{path}/{layer}_vy.txt\", vy.numpy())\n",
    "    np.savetxt(f\"{path}/{layer}_normbias.txt\", normbias.numpy())\n",
    "\n",
    "print(\"completed.\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02532a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# to excludle padding tokens\n",
    "all_attention_masks = torch.cat(attention_mask_list, dim=0)\n",
    "all_attention_masks = all_attention_masks.view(-1)\n",
    "\n",
    "# Compute the mean & inverse sqrt variance for each LayerNorm layer\n",
    "for layer, input_list in layernorm_inputs.items():\n",
    "    # concatenate all inputs for the current layer\n",
    "    all_inputs = torch.cat(input_list, dim=0)\n",
    "\n",
    "    # flatten the inputs to merge batch and sequence dimensions\n",
    "    total_samples, seq_length, hidden_size = all_inputs.shape\n",
    "    all_inputs = all_inputs.view(-1, hidden_size)\n",
    "\n",
    "    # exclude padding tokens\n",
    "    valid_indices = all_attention_masks.nonzero(as_tuple=False).squeeze()\n",
    "    valid_inputs = all_inputs[valid_indices]\n",
    "\n",
    "    # Compute mean and variance across all tokens and samples for each feature\n",
    "    mean = valid_inputs.mean(dim=0).double()\n",
    "    var = valid_inputs.var(dim=0, unbiased=False).double()\n",
    "\n",
    "    # Compute the inverse square root of variance + epsilon\n",
    "    epsilon = 1e-12\n",
    "    inv_sqrt_var = 1.0 / torch.sqrt(var + epsilon)\n",
    "    \n",
    "    #print(layer)\n",
    "    ln = None\n",
    "    # Compute vy & normbias\n",
    "    if (layer == \"layer0_self_output\"):\n",
    "        ln = model.bert.encoder.layer[0].attention.output.LayerNorm\n",
    "    elif (layer == \"layer0_output\"):\n",
    "        ln = model.bert.encoder.layer[0].output.LayerNorm\n",
    "    elif (layer == \"layer1_self_output\"):\n",
    "        ln = model.bert.encoder.layer[1].attention.output.LayerNorm\n",
    "    elif (layer == \"layer1_output\"):\n",
    "        ln = model.bert.encoder.layer[1].output.LayerNorm\n",
    "    \n",
    "    gamma = ln.weight.clone().detach().double()\n",
    "    beta = ln.bias.clone().detach().double()\n",
    "    \n",
    "    # Compute vy\n",
    "    vy = (gamma * inv_sqrt_var)\n",
    "    #normbias = beta - (gamma * mean * inv_sqrt_var)\n",
    "    normbias = beta\n",
    "    \n",
    "    # Expand vy to [128, 128]\n",
    "    max_length = 87\n",
    "    \"\"\"expanded_vy = vy.unsqueeze(0).repeat(max_length, 1)  # [87, 128]\n",
    "    padding_length = 128 - max_length\n",
    "    padding = torch.zeros(padding_length, 128, dtype=vy.dtype)\n",
    "    vy_expanded = torch.cat((expanded_vy, padding), dim=0)  # [128, 128]\"\"\"\n",
    "    # Expanded vy column-wise\n",
    "    expanded_vy = vy.unsqueeze(1).repeat(1, max_length)  # Shape: [128, 87]\n",
    "    padding_length = 128 - max_length\n",
    "    padding = torch.zeros(128, padding_length, dtype=vy.dtype)\n",
    "    vy_expanded = torch.cat((expanded_vy, padding), dim=1)  # Shape: [128, 128]\n",
    "\n",
    "\n",
    "    # Optionally, flatten to [128, 128] if needed by the HE circuit\n",
    "    # vy_expanded = vy_expanded.flatten()  # [16384]\n",
    "    #\n",
    "    path = \"./precomputed_layernorm\"\n",
    "    if not (os.path.exists(path)):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    # self_output -> selfoutput\n",
    "    layer = layer.replace('self_output', 'selfoutput')    \n",
    "        \n",
    "    # Save the means & inverse sqrt variance to text files\n",
    "    np.savetxt(f\"./{path}/{layer}_mean.txt\", mean.numpy())\n",
    "    np.savetxt(f\"./{path}/{layer}_inv_sqrt_var.txt\", inv_sqrt_var.numpy())\n",
    "    \n",
    "    # Save the vy & normbias\n",
    "    np.savetxt(f\"{path}/{layer}_vy.txt\", vy_expanded.numpy(), delimiter=',')\n",
    "    np.savetxt(f\"{path}/{layer}_normbias.txt\", normbias.numpy())\n",
    "\n",
    "print(\"completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82732740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70189029 0.70189029 0.70189029 ... 0.         0.         0.        ]\n",
      " [0.73176019 0.73176019 0.73176019 ... 0.         0.         0.        ]\n",
      " [0.78539148 0.78539148 0.78539148 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.80596859 0.80596859 0.80596859 ... 0.         0.         0.        ]\n",
      " [0.7398394  0.7398394  0.7398394  ... 0.         0.         0.        ]\n",
      " [0.7572742  0.7572742  0.7572742  ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Check sst2 vy\n",
    "vy = np.loadtxt(f\"./precomputed_layernorm/layer0_selfoutput_vy.txt\", delimiter=',')\n",
    "\n",
    "print(vy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f83b32ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.94889263 0.7733913  0.78807984 ... 0.         0.         0.        ]\n",
      " [0.83782058 0.68286245 0.69583164 ... 0.         0.         0.        ]\n",
      " [1.36303929 1.11093994 1.13203934 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.97102645 0.79143139 0.80646256 ... 0.         0.         0.        ]\n",
      " [0.85379329 0.69588095 0.70909739 ... 0.         0.         0.        ]\n",
      " [0.91188029 0.74322453 0.75734014 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Check sst2 vy\n",
    "vy = np.loadtxt(f\"./weights-sst2/layer0_selfoutput_vy.txt\", delimiter=',')\n",
    "\n",
    "print(vy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8062c",
   "metadata": {},
   "source": [
    "# Evaluate the pre-computed LayerNorm performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea3bf5",
   "metadata": {},
   "source": [
    "## mean & inverse_sqrt_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "951e313f-258d-471e-b473-b835cbeebb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./precomputed_layernorm\"\n",
    "\n",
    "# Load precomputed means and variances\n",
    "mean_0_0 = np.loadtxt(f\"{path}/layer0_selfoutput_mean.txt\")\n",
    "inv_sqrt_var_0_0 = np.loadtxt(f\"{path}/layer0_selfoutput_inv_sqrt_var.txt\")\n",
    "\n",
    "mean_0_1 = np.loadtxt(f\"{path}/layer0_output_mean.txt\")\n",
    "inv_sqrt_var_0_1 = np.loadtxt(f\"{path}/layer0_output_inv_sqrt_var.txt\")\n",
    "\n",
    "mean_1_0 = np.loadtxt(f\"{path}/layer1_selfoutput_mean.txt\")\n",
    "inv_sqrt_var_1_0 = np.loadtxt(f\"{path}/layer1_selfoutput_inv_sqrt_var.txt\")\n",
    "\n",
    "mean_1_1 = np.loadtxt(f\"{path}/layer1_output_mean.txt\")\n",
    "inv_sqrt_var_1_1 = np.loadtxt(f\"{path}/layer1_output_inv_sqrt_var.txt\")\n",
    "\n",
    "#print(\"mean_0_0: \", mean_0_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "444bcd82-9f16-4df0-8d18-0767a6f721ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# the author used validation dataset to test the performance\n",
    "# I use test dataset\n",
    "test_dataset = load_dataset(\"dair-ai/emotion\", split=\"test\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7253f1c0-94ce-4888-9be5-d810b059a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy plain: 0.902\n",
      "Accuracy precom: 0.842\n",
      "Performance loss: 0.0665188470066519\n"
     ]
    }
   ],
   "source": [
    "correct_plain = 0\n",
    "correct_precomp = 0\n",
    "\n",
    "for ind in range(len(test_dataset)):\n",
    "    text = \"[CLS] \" + test_dataset['text'][ind] + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "    x = model.bert.embeddings(tokens_tensor, torch.tensor([[1] * len(tokenized_text)]))\n",
    "\n",
    "    key = model.bert.encoder.layer[0].attention.self.key.weight.clone().detach().double().transpose(0, 1)\n",
    "    query = model.bert.encoder.layer[0].attention.self.query.weight.clone().detach().double().transpose(0, 1)\n",
    "    value = model.bert.encoder.layer[0].attention.self.value.weight.clone().detach().double().transpose(0, 1)\n",
    "\n",
    "    key_bias = model.bert.encoder.layer[0].attention.self.key.bias.clone().detach().double()\n",
    "    query_bias = model.bert.encoder.layer[0].attention.self.query.bias.clone().detach().double()\n",
    "    value_bias = model.bert.encoder.layer[0].attention.self.value.bias.clone().detach().double()\n",
    "\n",
    "    original_input_tensor = x.double()\n",
    "\n",
    "    input_tensor = x.double()\n",
    "\n",
    "    q = torch.matmul(input_tensor, query) + query_bias\n",
    "    k = torch.matmul(input_tensor, key) + key_bias\n",
    "    v = torch.matmul(input_tensor, value) + value_bias\n",
    "\n",
    "    q = q.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    k = k.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    v = v.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "\n",
    "    q = q.permute([0, 2, 1, 3])\n",
    "    k = k.permute([0, 2, 3, 1])\n",
    "\n",
    "    qk = torch.matmul(q, k)\n",
    "    qk = qk / 8\n",
    "\n",
    "    qk_softmaxed = torch.softmax(qk, -1)\n",
    "\n",
    "    v = v.permute([0, 2, 1, 3])\n",
    "\n",
    "    fin = torch.matmul(qk_softmaxed, v)\n",
    "    fin = fin.permute([0, 2, 1, 3])\n",
    "    fin = fin.reshape([1, input_tensor.size()[1], 128])\n",
    "\n",
    "    mean = mean_0_0\n",
    "    var = inv_sqrt_var_0_0\n",
    "\n",
    "    w_output_dense = model.bert.encoder.layer[0].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[0].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + original_input_tensor\n",
    "\n",
    "    fin3_whole = []\n",
    "\n",
    "    for i in range(len(original_input_tensor.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "        idx = i\n",
    "\n",
    "        if i > len(mean) - 1:\n",
    "            idx = len(mean) - 1\n",
    "\n",
    "        fin3_corr = (fin2.squeeze().detach() - mean[idx]) * var[idx]\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr.detach())\n",
    "\n",
    "    fin3_whole = torch.cat(tuple(fin3_whole), 0).unsqueeze(0)\n",
    "    fin_4 = torch.matmul(fin3_whole, model.bert.encoder.layer[0].intermediate.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[0].intermediate.dense.bias\n",
    "\n",
    "    fin_5 = torch.nn.functional.gelu(fin_4)\n",
    "    fin_6 = torch.matmul(fin_5, model.bert.encoder.layer[0].output.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[0].output.dense.bias\n",
    "    fin_6 = fin_6 + fin3_whole\n",
    "\n",
    "    mean = mean_0_1\n",
    "    var = inv_sqrt_var_0_1\n",
    "\n",
    "    fin7_whole = []\n",
    "\n",
    "    for i in range(len(input_tensor.squeeze())):\n",
    "        fin_7 = fin_6.squeeze()[i]\n",
    "\n",
    "        idx = i\n",
    "\n",
    "        if i > len(mean) - 1:\n",
    "            idx = len(mean) - 1\n",
    "\n",
    "        fin7_corr = (fin_7.squeeze().detach() - mean[idx]) * var[idx]\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[0].output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[0].output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin7_corr = fin7_corr * w_output_layernorm + b_output_layernorm\n",
    "\n",
    "        fin7_whole.append(fin7_corr.detach())\n",
    "\n",
    "    fin7_whole = torch.cat(tuple(fin7_whole), 0).unsqueeze(0)\n",
    "\n",
    "    key = model.bert.encoder.layer[1].attention.self.key.weight.clone().detach().double().transpose(0, 1)\n",
    "    query = model.bert.encoder.layer[1].attention.self.query.weight.clone().detach().double().transpose(0, 1)\n",
    "    value = model.bert.encoder.layer[1].attention.self.value.weight.clone().detach().double().transpose(0, 1)\n",
    "\n",
    "    key_bias = model.bert.encoder.layer[1].attention.self.key.bias.clone().detach().double()\n",
    "    query_bias = model.bert.encoder.layer[1].attention.self.query.bias.clone().detach().double()\n",
    "    value_bias = model.bert.encoder.layer[1].attention.self.value.bias.clone().detach().double()\n",
    "\n",
    "    original_input_tensor = fin7_whole\n",
    "    input_tensor = fin7_whole\n",
    "\n",
    "    q = torch.matmul(input_tensor, query) + query_bias\n",
    "    k = torch.matmul(input_tensor, key) + key_bias\n",
    "    v = torch.matmul(input_tensor, value) + value_bias\n",
    "\n",
    "    q = q.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    k = k.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    v = v.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "\n",
    "    q = q.permute([0, 2, 1, 3])\n",
    "    k = k.permute([0, 2, 3, 1])\n",
    "\n",
    "    qk = torch.matmul(q, k)\n",
    "    qk = qk / 8\n",
    "\n",
    "    qk_softmaxed = torch.softmax(qk, -1)\n",
    "\n",
    "    v = v.permute([0, 2, 1, 3])\n",
    "\n",
    "    fin = torch.matmul(qk_softmaxed, v)\n",
    "    fin = fin.permute([0, 2, 1, 3])\n",
    "    fin = fin.reshape([1, input_tensor.size()[1], 128])\n",
    "\n",
    "    mean = mean_1_0\n",
    "    var = inv_sqrt_var_1_0\n",
    "\n",
    "    w_output_dense = model.bert.encoder.layer[1].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[1].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + original_input_tensor\n",
    "\n",
    "    fin3_whole = []\n",
    "\n",
    "    for i in range(len(original_input_tensor.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "        idx = i\n",
    "\n",
    "        if i > len(mean) - 1:\n",
    "            idx = len(mean) - 1\n",
    "\n",
    "        fin3_corr = (fin2.squeeze().detach() - mean[idx]) * var[idx]\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[1].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[1].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr.detach())\n",
    "\n",
    "    fin3_whole = torch.cat(tuple(fin3_whole), 0).unsqueeze(0)\n",
    "    fin_4 = torch.matmul(fin3_whole, model.bert.encoder.layer[1].intermediate.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[1].intermediate.dense.bias\n",
    "\n",
    "    fin_5 = torch.nn.functional.gelu(fin_4)\n",
    "\n",
    "    fin_6 = torch.matmul(fin_5, model.bert.encoder.layer[1].output.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[1].output.dense.bias\n",
    "    fin_6 = fin_6 + fin3_whole\n",
    "\n",
    "    fin7_whole = []\n",
    "\n",
    "    mean = mean_1_1\n",
    "    var = inv_sqrt_var_1_1\n",
    "\n",
    "    for i in range(len(input_tensor.squeeze())):\n",
    "        fin_7 = fin_6.squeeze()[i]\n",
    "\n",
    "        idx = i\n",
    "\n",
    "        if i > len(mean) - 1:\n",
    "            idx = len(mean) - 1\n",
    "\n",
    "        fin7_corr = (fin_7.squeeze().detach() - mean[idx]) * var[idx]\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[1].output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[1].output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin7_corr = fin7_corr * w_output_layernorm + b_output_layernorm\n",
    "\n",
    "        fin7_whole.append(fin7_corr.detach())\n",
    "\n",
    "    fin7_whole = torch.cat(tuple(fin7_whole), 0).unsqueeze(0)\n",
    "\n",
    "    densed_pooler = torch.tanh(torch.matmul(fin7_whole.double(), model.bert.pooler.dense.weight.transpose(0, 1).double()) + model.bert.pooler.dense.bias)\n",
    "\n",
    "    approx = densed_pooler[0][0].detach()\n",
    "    precise = model.bert.pooler(model.bert.encoder(x)[0]).detach()[0]\n",
    "\n",
    "    output = torch.matmul(approx, model.classifier.weight.transpose(0, 1).double()) + model.classifier.bias.double()\n",
    "    output_real = model(tokens_tensor, torch.tensor([[1] * len(tokenized_text)])).logits[0].detach()\n",
    "\n",
    "    # Multi-labels\n",
    "    predicted = torch.argmax(output).item()\n",
    "    predicted_real = torch.argmax(output_real).item()\n",
    "\n",
    "    if predicted_real == test_dataset['label'][ind]:\n",
    "      correct_plain += 1\n",
    "\n",
    "    if predicted == test_dataset['label'][ind]:\n",
    "      correct_precomp += 1\n",
    "\n",
    "    \"\"\"if output_real[0].item() > output_real[1].item() and test_dataset['label'][ind] == 0:\n",
    "        correct_plain = correct_plain + 1\n",
    "    if output_real[0].item() < output_real[1].item() and test_dataset['label'][ind] == 1:\n",
    "        correct_plain = correct_plain + 1\n",
    "\n",
    "    if output[0].item() > output[1].item() and test_dataset['label'][ind] == 0:\n",
    "        correct_precomp = correct_precomp + 1\n",
    "    if output[0].item() < output[1].item() and test_dataset['label'][ind] == 1:\n",
    "        correct_precomp = correct_precomp + 1\"\"\"\n",
    "\n",
    "accuracy_plain = float(correct_plain) / len(test_dataset['label'])\n",
    "accuracy_precomp = float(correct_precomp) / len(test_dataset['label'])\n",
    "\n",
    "print(\"Accuracy plain: {}\\nAccuracy precom: {}\".format(accuracy_plain, accuracy_precomp))\n",
    "\n",
    "print(\"Performance loss: {}\".format(1 - accuracy_precomp / accuracy_plain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1f4a3",
   "metadata": {},
   "source": [
    "## vy & mean & normbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d19a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./precomputed_layernorm\"\n",
    "\n",
    "# Load precomputed means and variances\n",
    "vy_0_0 = np.loadtxt(f\"{path}/layer0_selfoutput_vy.txt\", delimiter=',')\n",
    "normbias_0_0 = np.loadtxt(f\"{path}/layer0_selfoutput_normbias.txt\")\n",
    "\n",
    "vy_0_1 = np.loadtxt(f\"{path}/layer0_output_vy.txt\", delimiter=',')\n",
    "normbias_0_1 = np.loadtxt(f\"{path}/layer0_output_normbias.txt\")\n",
    "\n",
    "vy_1_0 = np.loadtxt(f\"{path}/layer1_selfoutput_vy.txt\", delimiter=',')\n",
    "normbias_1_0 = np.loadtxt(f\"{path}/layer1_selfoutput_normbias.txt\")\n",
    "\n",
    "vy_1_1 = np.loadtxt(f\"{path}/layer1_output_vy.txt\", delimiter=',')\n",
    "normbias_1_1 = np.loadtxt(f\"{path}/layer1_output_normbias.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc4fc9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1466, -0.2112, -7.0304,  ..., -2.0351, -0.1173,  0.5875],\n",
      "        [-0.1202, -0.2242, -7.3285,  ..., -2.0351, -0.1173,  0.5875],\n",
      "        [-0.0730, -0.2474, -7.8637,  ..., -2.0351, -0.1173,  0.5875],\n",
      "        ...,\n",
      "        [-0.0548, -0.2563, -8.0690,  ..., -2.0351, -0.1173,  0.5875],\n",
      "        [-0.1131, -0.2277, -7.4091,  ..., -2.0351, -0.1173,  0.5875],\n",
      "        [-0.0977, -0.2352, -7.5831,  ..., -2.0351, -0.1173,  0.5875]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/qv8zrd4d5t12dqxjq4rxf56r0000gn/T/ipykernel_60548/3304471750.py:71: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  fin3_corr = fin3_corr * vy_0_0 + b_output_layernorm\n"
     ]
    }
   ],
   "source": [
    "text = \"i felt anger when at the end of a telephone call\"\n",
    "text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "tokenized = tokenizer(text)\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "x = model.bert.embeddings(tokens_tensor, torch.tensor([[1] * len(tokenized_text)]))\n",
    "\n",
    "key = model.bert.encoder.layer[0].attention.self.key.weight.clone().detach().double().transpose(0, 1)\n",
    "query = model.bert.encoder.layer[0].attention.self.query.weight.clone().detach().double().transpose(0, 1)\n",
    "value = model.bert.encoder.layer[0].attention.self.value.weight.clone().detach().double().transpose(0, 1)\n",
    "\n",
    "key_bias = model.bert.encoder.layer[0].attention.self.key.bias.clone().detach().double()\n",
    "query_bias = model.bert.encoder.layer[0].attention.self.query.bias.clone().detach().double()\n",
    "value_bias = model.bert.encoder.layer[0].attention.self.value.bias.clone().detach().double()\n",
    "\n",
    "original_input_tensor = x.double()\n",
    "\n",
    "input_tensor = x.double()\n",
    "\n",
    "q = torch.matmul(input_tensor, query) + query_bias\n",
    "k = torch.matmul(input_tensor, key) + key_bias\n",
    "v = torch.matmul(input_tensor, value) + value_bias\n",
    "\n",
    "q = q.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "k = k.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "v = v.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "\n",
    "q = q.permute([0, 2, 1, 3])\n",
    "k = k.permute([0, 2, 3, 1])\n",
    "\n",
    "qk = torch.matmul(q, k)\n",
    "qk = qk / 8\n",
    "\n",
    "qk_softmaxed = torch.softmax(qk, -1)\n",
    "\n",
    "v = v.permute([0, 2, 1, 3])\n",
    "\n",
    "fin = torch.matmul(qk_softmaxed, v)\n",
    "fin = fin.permute([0, 2, 1, 3])\n",
    "fin = fin.reshape([1, input_tensor.size()[1], 128])\n",
    "#print(fin[0][0].detach())\n",
    "mean = mean_0_0\n",
    "var = inv_sqrt_var_0_0\n",
    "\n",
    "w_output_dense = model.bert.encoder.layer[0].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "b_output_dense = model.bert.encoder.layer[0].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "fin2_backup = fin2.clone()\n",
    "fin2_backup = fin2_backup + original_input_tensor\n",
    "\n",
    "# Initialize fin3_whole as an empty list **before** the loop\n",
    "fin3_whole = []\n",
    "\n",
    "for i in range(len(original_input_tensor.squeeze())):\n",
    "    fin2 = fin2_backup.squeeze()[i]\n",
    "    \n",
    "    # Using Precomputed vy & normbias\n",
    "    fin3_corr = (fin2.squeeze().detach() - mean[i])\n",
    "    #fin3_corr = (fin2.squeeze().detach() - mean_0_0[idx]) * vy_0_0[idx] + normbias_0_0[idx]\n",
    "    #fin3_corr = fin2.squeeze().detach() - mean_0_0[idx]\n",
    "\n",
    "    w_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "    b_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "    #print((w_output_layernorm*inv_sqrt_var_0_0)[0].detach()[:20])\n",
    "    #print(vy_0_0[:20])\n",
    "    #fin3_corr = fin3_corr * vy_0_0 + normbias_0_0\n",
    "    fin3_corr = fin3_corr * vy_0_0 + b_output_layernorm\n",
    "    fin3_whole.append(fin3_corr.detach())\n",
    "\n",
    "        # Remove the stacking inside the loop\n",
    "    #fin3_whole = torch.stack(fin3_whole, dim=0).unsqueeze(0)\n",
    "\n",
    "# Perform stacking **after** the loop\n",
    "fin3_whole = torch.stack(fin3_whole, dim=0).unsqueeze(0)\n",
    "\n",
    "print(fin3_whole[0][0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1291631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "[[-6.34076624e-02  7.94889678e-01  6.75515803e-01 ... -2.03510666e+00\n",
      "  -1.17310695e-01  5.87514222e-01]\n",
      " [-3.35377611e-02  8.24759579e-01  7.05385705e-01 ... -2.03510666e+00\n",
      "  -1.17310695e-01  5.87514222e-01]\n",
      " [ 2.00935273e-02  8.78390868e-01  7.59016993e-01 ... -2.03510666e+00\n",
      "  -1.17310695e-01  5.87514222e-01]\n",
      " ...\n",
      " [-1.15913167e-01  7.42384174e-01  6.23010299e-01 ... -2.03510666e+00\n",
      "  -1.17310695e-01  5.87514222e-01]\n",
      " [ 9.64036601e-04  8.59261377e-01  7.39887502e-01 ... -2.03510666e+00\n",
      "  -1.17310695e-01  5.87514222e-01]\n",
      " [-4.27531789e-02  8.15544162e-01  6.96170287e-01 ... -2.03510666e+00\n",
      "  -1.17310695e-01  5.87514222e-01]]\n",
      "128\n",
      "tensor([-0.0634,  0.8248,  0.7590,  1.1734,  1.2206,  0.5368,  0.7642,  0.2309,\n",
      "        -0.8590,  1.5123,  0.6431,  0.5132,  1.0490,  0.3740,  1.0030,  0.5172,\n",
      "         0.3282,  0.4670, -0.0680,  1.3154,  0.8280,  0.4696,  0.6618,  2.4164,\n",
      "         2.2775,  0.7285,  0.7830,  1.2394,  1.4917,  0.6308],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/qv8zrd4d5t12dqxjq4rxf56r0000gn/T/ipykernel_60548/1376504826.py:7: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  res2 = gamma * inv_sqrt_var_0_0 + bias\n"
     ]
    }
   ],
   "source": [
    "res = vy_0_0 + normbias_0_0\n",
    "print(len(res))\n",
    "print(res[:30])     \n",
    "\n",
    "gamma = model.bert.encoder.layer[0].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "bias = model.bert.encoder.layer[0].attention.output.LayerNorm.bias.clone().detach().double().unsqueeze(0)\n",
    "res2 = gamma * inv_sqrt_var_0_0 + bias\n",
    "res2 = res2[0].detach()\n",
    "print(len(res2))\n",
    "print(res2[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31656166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -0.1466,  -0.1790, -10.1302,  -0.5519,   0.3425,   0.4700,   0.0398,\n",
      "           1.0241,  -0.1439,   1.0091,  -0.8814,   0.1961,   0.3608,  -0.0317,\n",
      "          -1.0740,   0.7573,  -0.7651,   1.1910,  -0.4964,   0.4097,  -0.6854,\n",
      "          -0.7305,   1.9784,   1.3808,  -0.3049,  -0.4008,   0.0794,   0.6865,\n",
      "          -0.2405,  -0.9449,  -0.8641,   0.2330,  -3.3474,  -0.3193,  -0.6875,\n",
      "           0.0575,   0.9239,  -1.5270,   0.1991,  -0.0481,   1.5426,  -0.0205,\n",
      "           2.3671,   0.2271,   0.1164,   0.3865,   1.6621,   0.2020,  -0.4584,\n",
      "           0.8023,   0.1237,   0.6494,  -1.5522,   0.7460,  -0.2230,   0.0901,\n",
      "          -0.3679,   0.9887,   0.9923,   1.1479,   0.7968,  -0.7203,  -1.8336,\n",
      "           1.1846,   0.5112,   0.4405,   0.0339,  -0.4311,   0.4589,  -0.6145,\n",
      "           0.0184,   0.6405,  -0.1323,  -3.2421,  -0.3697,  -0.2277,   0.2777,\n",
      "          -0.5941,   1.3493,  -1.4300,  -0.3330,  -0.8201,   0.7121,   0.9157,\n",
      "           0.1389,   0.9806,   0.5941,  -1.1762,   0.1621,  -0.7184,   0.5137,\n",
      "          -0.0514,  -0.1530,  -0.3651,   1.0634,   0.4997,   1.0214,   0.3713,\n",
      "          -0.1082,  -0.3050,  -0.8316,   0.0751,  -0.3583,   0.1536,  -0.1931,\n",
      "           0.5703,  -0.5494,   0.0289,   0.3654,  -0.5320,  -0.3739,   0.8036,\n",
      "          -0.5215,  -0.0819,   0.3490,  -0.3246,   0.4128,  -0.7823,   0.2311,\n",
      "           0.2567,  -1.6096,   0.1443,   0.6324,   0.1869,   1.1384,  -1.1437,\n",
      "          -1.3705,  -0.3517]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "text = \"i felt anger when at the end of a telephone call\"\n",
    "text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "tokenized = tokenizer(text)\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "x = model.bert.embeddings(tokens_tensor, torch.tensor([[1] * len(tokenized_text)]))\n",
    "\n",
    "key = model.bert.encoder.layer[0].attention.self.key.weight.clone().detach().double().transpose(0, 1)\n",
    "query = model.bert.encoder.layer[0].attention.self.query.weight.clone().detach().double().transpose(0, 1)\n",
    "value = model.bert.encoder.layer[0].attention.self.value.weight.clone().detach().double().transpose(0, 1)\n",
    "\n",
    "key_bias = model.bert.encoder.layer[0].attention.self.key.bias.clone().detach().double()\n",
    "query_bias = model.bert.encoder.layer[0].attention.self.query.bias.clone().detach().double()\n",
    "value_bias = model.bert.encoder.layer[0].attention.self.value.bias.clone().detach().double()\n",
    "\n",
    "original_input_tensor = x.double()\n",
    "\n",
    "input_tensor = x.double()\n",
    "\n",
    "q = torch.matmul(input_tensor, query) + query_bias\n",
    "k = torch.matmul(input_tensor, key) + key_bias\n",
    "v = torch.matmul(input_tensor, value) + value_bias\n",
    "\n",
    "q = q.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "k = k.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "v = v.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "\n",
    "q = q.permute([0, 2, 1, 3])\n",
    "k = k.permute([0, 2, 3, 1])\n",
    "\n",
    "qk = torch.matmul(q, k)\n",
    "qk = qk / 8\n",
    "\n",
    "qk_softmaxed = torch.softmax(qk, -1)\n",
    "\n",
    "v = v.permute([0, 2, 1, 3])\n",
    "\n",
    "fin = torch.matmul(qk_softmaxed, v)\n",
    "fin = fin.permute([0, 2, 1, 3])\n",
    "fin = fin.reshape([1, input_tensor.size()[1], 128])\n",
    "#print(fin[0][0].detach())\n",
    "mean = mean_0_0\n",
    "var = inv_sqrt_var_0_0\n",
    "\n",
    "w_output_dense = model.bert.encoder.layer[0].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "b_output_dense = model.bert.encoder.layer[0].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "fin2_backup = fin2.clone()\n",
    "fin2_backup = fin2_backup + original_input_tensor\n",
    "#print(fin2_backup[0][0].detach())\n",
    "# Initialize fin3_whole as an empty list **before** the loop\n",
    "fin3_whole = []\n",
    "\n",
    "for i in range(len(original_input_tensor.squeeze())):\n",
    "    fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "    idx = i\n",
    "\n",
    "    if i > len(mean) - 1:\n",
    "        idx = len(mean) - 1\n",
    "    \n",
    "    # Using Precomputed vy & normbias\n",
    "    fin3_corr = fin2.squeeze().detach() - mean_0_0[idx]\n",
    "    #print(fin3_corr)\n",
    "    fin3_corr *= var[idx]\n",
    "    #fin3_corr = (fin2.squeeze().detach() - mean[i]) * var[i]\n",
    "    #fin3_corr = (fin2.squeeze().detach() - mean_0_0[idx]) * vy_0_0[idx] + normbias_0_0[idx]\n",
    "    #fin3_corr = fin2.squeeze().detach() - mean_0_0[idx]\n",
    "    \n",
    "    w_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "    b_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "    #fin3_corr = fin3_corr * vy_0_0 + normbias_0_0\n",
    "    fin3_corr = (fin3_corr * w_output_layernorm) + b_output_layernorm\n",
    "    fin3_whole.append(fin3_corr.detach())\n",
    "    \n",
    "    # Remove the stacking inside the loop\n",
    "    #fin3_whole = torch.stack(fin3_whole, dim=0).unsqueeze(0)\n",
    "\n",
    "# Perform stacking **after** the loop\n",
    "fin3_whole = torch.stack(fin3_whole, dim=0).unsqueeze(0)\n",
    "\n",
    "print(fin3_whole[0][0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad82d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/qv8zrd4d5t12dqxjq4rxf56r0000gn/T/ipykernel_60548/3042918575.py:82: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  fin3_corr = fin3_corr * vy_0_0[idx] + normbias_0_0[idx]\n",
      "/var/folders/3t/qv8zrd4d5t12dqxjq4rxf56r0000gn/T/ipykernel_60548/3042918575.py:117: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  fin7_corr = fin7_corr * vy_0_1[idx] + normbias_0_1[idx]\n",
      "/var/folders/3t/qv8zrd4d5t12dqxjq4rxf56r0000gn/T/ipykernel_60548/3042918575.py:185: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  fin3_corr = fin3_corr * vy_1_0[idx] + normbias_1_0[idx]\n",
      "/var/folders/3t/qv8zrd4d5t12dqxjq4rxf56r0000gn/T/ipykernel_60548/3042918575.py:219: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  fin7_corr = fin7_corr * vy_1_1[idx] + normbias_1_1[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy plain: 0.902\n",
      "Accuracy precom: 0.645\n",
      "Performance loss: 0.28492239467849223\n"
     ]
    }
   ],
   "source": [
    "correct_plain = 0\n",
    "correct_precomp = 0\n",
    "\n",
    "for ind in range(len(test_dataset)):\n",
    "    text = \"[CLS] \" + test_dataset['text'][ind] + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "    x = model.bert.embeddings(tokens_tensor, torch.tensor([[1] * len(tokenized_text)]))\n",
    "\n",
    "    key = model.bert.encoder.layer[0].attention.self.key.weight.clone().detach().double().transpose(0, 1)\n",
    "    query = model.bert.encoder.layer[0].attention.self.query.weight.clone().detach().double().transpose(0, 1)\n",
    "    value = model.bert.encoder.layer[0].attention.self.value.weight.clone().detach().double().transpose(0, 1)\n",
    "\n",
    "    key_bias = model.bert.encoder.layer[0].attention.self.key.bias.clone().detach().double()\n",
    "    query_bias = model.bert.encoder.layer[0].attention.self.query.bias.clone().detach().double()\n",
    "    value_bias = model.bert.encoder.layer[0].attention.self.value.bias.clone().detach().double()\n",
    "\n",
    "    original_input_tensor = x.double()\n",
    "\n",
    "    input_tensor = x.double()\n",
    "\n",
    "    q = torch.matmul(input_tensor, query) + query_bias\n",
    "    k = torch.matmul(input_tensor, key) + key_bias\n",
    "    v = torch.matmul(input_tensor, value) + value_bias\n",
    "\n",
    "    q = q.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    k = k.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    v = v.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "\n",
    "    q = q.permute([0, 2, 1, 3])\n",
    "    k = k.permute([0, 2, 3, 1])\n",
    "\n",
    "    qk = torch.matmul(q, k)\n",
    "    qk = qk / 8\n",
    "\n",
    "    qk_softmaxed = torch.softmax(qk, -1)\n",
    "\n",
    "    v = v.permute([0, 2, 1, 3])\n",
    "\n",
    "    fin = torch.matmul(qk_softmaxed, v)\n",
    "    fin = fin.permute([0, 2, 1, 3])\n",
    "    fin = fin.reshape([1, input_tensor.size()[1], 128])\n",
    "\n",
    "    mean = mean_0_0\n",
    "    var = inv_sqrt_var_0_0\n",
    "\n",
    "    w_output_dense = model.bert.encoder.layer[0].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[0].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + original_input_tensor\n",
    "    \n",
    "    #fin2_centered = fin2.squeeze().detach() - mean\n",
    "    #fin3_corr = fin2_centered * vy_0_0\n",
    "    #fin3_corr = fin3_corr + normbias_0_0\n",
    "    #fin3_whole = []\n",
    "    #fin3_whole.append(fin3_corr.detach())\n",
    "    \n",
    "    fin3_whole = []\n",
    "\n",
    "    for i in range(len(original_input_tensor.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "        idx = i\n",
    "\n",
    "        if i > len(mean) - 1:\n",
    "            idx = len(mean) - 1\n",
    "\n",
    "        # Using Precomputed vy & normbias\n",
    "        #fin3_corr = (fin2.squeeze().detach() - mean[idx]) * var[idx]\n",
    "        #fin3_corr = (fin2.squeeze().detach() - mean_0_0[idx]) * vy_0_0[idx] + normbias_0_0[idx]\n",
    "        fin3_corr = fin2.squeeze().detach() - mean_0_0[idx]\n",
    "\n",
    "        #w_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        #b_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr * vy_0_0[idx] + normbias_0_0[idx]\n",
    "        #fin3_corr = fin3_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr.detach())\n",
    "    \n",
    "    #print(fin3_corr.shape)\n",
    "    # Using stack\n",
    "    #fin3_whole = torch.cat(tuple(fin3_whole), 0).unsqueeze(0)\n",
    "    #print(fin3_whole.shape)\n",
    "    fin3_whole = torch.stack(fin3_whole, dim=0).unsqueeze(0)\n",
    "    fin_4 = torch.matmul(fin3_whole, model.bert.encoder.layer[0].intermediate.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[0].intermediate.dense.bias\n",
    "\n",
    "    fin_5 = torch.nn.functional.gelu(fin_4)\n",
    "    fin_6 = torch.matmul(fin_5, model.bert.encoder.layer[0].output.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[0].output.dense.bias\n",
    "    fin_6 = fin_6 + fin3_whole\n",
    "\n",
    "    mean = mean_0_1\n",
    "    var = inv_sqrt_var_0_1\n",
    "\n",
    "    fin7_whole = []\n",
    "\n",
    "    for i in range(len(input_tensor.squeeze())):\n",
    "        fin_7 = fin_6.squeeze()[i]\n",
    "\n",
    "        idx = i\n",
    "\n",
    "        if i > len(mean) - 1:\n",
    "            idx = len(mean) - 1\n",
    "\n",
    "        # Using Precomputed vy & normbias\n",
    "        #fin7_corr = (fin_7.squeeze().detach() - mean[idx]) * var[idx]\n",
    "        #fin7_corr = (fin_7.squeeze().detach() - mean_0_1[idx]) * vy_0_1[idx] + normbias_0_1[idx]\n",
    "        fin7_corr = fin_7.squeeze().detach() - mean_0_1[idx]\n",
    "        #w_output_layernorm = model.bert.encoder.layer[0].output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        #b_output_layernorm = model.bert.encoder.layer[0].output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin7_corr = fin7_corr * vy_0_1[idx] + normbias_0_1[idx]\n",
    "        #fin7_corr = fin7_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin7_whole.append(fin7_corr.detach())\n",
    "\n",
    "    # Using stack\n",
    "    fin7_whole = torch.stack(fin7_whole, dim=0).unsqueeze(0)\n",
    "    #fin7_whole = torch.cat(tuple(fin7_whole), 0).unsqueeze(0)\n",
    "\n",
    "    key = model.bert.encoder.layer[1].attention.self.key.weight.clone().detach().double().transpose(0, 1)\n",
    "    query = model.bert.encoder.layer[1].attention.self.query.weight.clone().detach().double().transpose(0, 1)\n",
    "    value = model.bert.encoder.layer[1].attention.self.value.weight.clone().detach().double().transpose(0, 1)\n",
    "\n",
    "    key_bias = model.bert.encoder.layer[1].attention.self.key.bias.clone().detach().double()\n",
    "    query_bias = model.bert.encoder.layer[1].attention.self.query.bias.clone().detach().double()\n",
    "    value_bias = model.bert.encoder.layer[1].attention.self.value.bias.clone().detach().double()\n",
    "\n",
    "    original_input_tensor = fin7_whole\n",
    "    input_tensor = fin7_whole\n",
    "    \n",
    "    q = torch.matmul(input_tensor, query) + query_bias\n",
    "    k = torch.matmul(input_tensor, key) + key_bias\n",
    "    v = torch.matmul(input_tensor, value) + value_bias\n",
    "\n",
    "    q = q.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    k = k.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    v = v.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "\n",
    "    q = q.permute([0, 2, 1, 3])\n",
    "    k = k.permute([0, 2, 3, 1])\n",
    "\n",
    "    qk = torch.matmul(q, k)\n",
    "    qk = qk / 8\n",
    "\n",
    "    qk_softmaxed = torch.softmax(qk, -1)\n",
    "\n",
    "    v = v.permute([0, 2, 1, 3])\n",
    "\n",
    "    fin = torch.matmul(qk_softmaxed, v)\n",
    "    fin = fin.permute([0, 2, 1, 3])\n",
    "    fin = fin.reshape([1, input_tensor.size()[1], 128])\n",
    "\n",
    "    mean = mean_1_0\n",
    "    var = inv_sqrt_var_1_0\n",
    "\n",
    "    w_output_dense = model.bert.encoder.layer[1].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[1].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + original_input_tensor\n",
    "\n",
    "    fin3_whole = []\n",
    "\n",
    "    for i in range(len(original_input_tensor.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "        idx = i\n",
    "\n",
    "        if i > len(mean) - 1:\n",
    "            idx = len(mean) - 1\n",
    "\n",
    "        # Using Precomputed vy & normbias\n",
    "        #fin3_corr = (fin2.squeeze().detach() - mean[idx]) * var[idx]\n",
    "        #fin3_corr = (fin2.squeeze().detach() - mean_1_0[idx]) * vy_1_0[idx] + normbias_1_0[idx]\n",
    "        fin3_corr = fin2.squeeze().detach() - mean_1_0[idx]\n",
    "        #w_output_layernorm = model.bert.encoder.layer[1].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        #b_output_layernorm = model.bert.encoder.layer[1].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr * vy_1_0[idx] + normbias_1_0[idx]\n",
    "        #fin3_corr = fin3_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr.detach())\n",
    "\n",
    "    # Using stack\n",
    "    #fin3_whole = torch.cat(tuple(fin3_whole), 0).unsqueeze(0)\n",
    "    fin3_whole = torch.stack(fin3_whole, dim=0).unsqueeze(0)\n",
    "    fin_4 = torch.matmul(fin3_whole, model.bert.encoder.layer[1].intermediate.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[1].intermediate.dense.bias\n",
    "\n",
    "    fin_5 = torch.nn.functional.gelu(fin_4)\n",
    "\n",
    "    fin_6 = torch.matmul(fin_5, model.bert.encoder.layer[1].output.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[1].output.dense.bias\n",
    "    fin_6 = fin_6 + fin3_whole\n",
    "\n",
    "    fin7_whole = []\n",
    "\n",
    "    mean = mean_1_1\n",
    "    var = inv_sqrt_var_1_1\n",
    "\n",
    "    for i in range(len(input_tensor.squeeze())):\n",
    "        fin_7 = fin_6.squeeze()[i]\n",
    "\n",
    "        idx = i\n",
    "\n",
    "        if i > len(mean) - 1:\n",
    "            idx = len(mean) - 1\n",
    "\n",
    "        # Using Precomputed vy & normbias\n",
    "        #fin7_corr = (fin_7.squeeze().detach() - mean[idx]) * var[idx]\n",
    "        #fin7_corr = (fin_7.squeeze().detach() - mean_1_1[idx]) * vy_1_1[idx] + normbias_1_1[idx]\n",
    "        fin7_corr = fin_7.squeeze().detach() - mean_1_1[idx]\n",
    "        #w_output_layernorm = model.bert.encoder.layer[1].output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        #b_output_layernorm = model.bert.encoder.layer[1].output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin7_corr = fin7_corr * vy_1_1[idx] + normbias_1_1[idx]\n",
    "        #fin7_corr = fin7_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin7_whole.append(fin7_corr.detach())\n",
    "    \n",
    "    # Using stack\n",
    "    fin7_whole = torch.stack(fin7_whole, dim=0).unsqueeze(0)\n",
    "    #fin7_whole = torch.cat(tuple(fin7_whole), 0).unsqueeze(0)\n",
    "\n",
    "    densed_pooler = torch.tanh(torch.matmul(fin7_whole.double(), model.bert.pooler.dense.weight.transpose(0, 1).double()) + model.bert.pooler.dense.bias)\n",
    "\n",
    "    approx = densed_pooler[0][0].detach()\n",
    "    precise = model.bert.pooler(model.bert.encoder(x)[0]).detach()[0]\n",
    "\n",
    "    output = torch.matmul(approx, model.classifier.weight.transpose(0, 1).double()) + model.classifier.bias.double()\n",
    "    output_real = model(tokens_tensor, torch.tensor([[1] * len(tokenized_text)])).logits[0].detach()\n",
    "\n",
    "    # Multi-labels\n",
    "    predicted = torch.argmax(output).item()\n",
    "    predicted_real = torch.argmax(output_real).item()\n",
    "\n",
    "    if predicted_real == test_dataset['label'][ind]:\n",
    "      correct_plain += 1\n",
    "\n",
    "    if predicted == test_dataset['label'][ind]:\n",
    "      correct_precomp += 1\n",
    "\n",
    "    \"\"\"if output_real[0].item() > output_real[1].item() and test_dataset['label'][ind] == 0:\n",
    "        correct_plain = correct_plain + 1\n",
    "    if output_real[0].item() < output_real[1].item() and test_dataset['label'][ind] == 1:\n",
    "        correct_plain = correct_plain + 1\n",
    "\n",
    "    if output[0].item() > output[1].item() and test_dataset['label'][ind] == 0:\n",
    "        correct_precomp = correct_precomp + 1\n",
    "    if output[0].item() < output[1].item() and test_dataset['label'][ind] == 1:\n",
    "        correct_precomp = correct_precomp + 1\"\"\"\n",
    "\n",
    "accuracy_plain = float(correct_plain) / len(test_dataset['label'])\n",
    "accuracy_precomp = float(correct_precomp) / len(test_dataset['label'])\n",
    "\n",
    "print(\"Accuracy plain: {}\\nAccuracy precom: {}\".format(accuracy_plain, accuracy_precomp))\n",
    "\n",
    "print(\"Performance loss: {}\".format(1 - accuracy_precomp / accuracy_plain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14ba41",
   "metadata": {},
   "source": [
    "#### Acceptable result?\n",
    "\n",
    "##### mean & var\n",
    "Accuracy plain: 0.902\n",
    "Accuracy precom: 0.842\n",
    "Performance loss: 0.0665188470066519\n",
    "\n",
    "##### vy & normbias\n",
    "Accuracy plain: 0.902\n",
    "Accuracy precom: 0.757\n",
    "Performance loss: 0.1607538802660754\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce7f20",
   "metadata": {},
   "source": [
    "# Chebyshev Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "736ac3ad-2801-476a-a036-55ff0bbc1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def precision(correct, approx):\n",
    "    if type(approx) == list:\n",
    "        approx = np.array(approx)\n",
    "    absolute = sum(abs(correct - approx))/len(correct)\n",
    "    relative = absolute / (sum(abs(correct))/len(correct))\n",
    "    return 1 - relative\"\"\"\n",
    "\n",
    "def precision(correct, approx):\n",
    "    correct = np.asarray(correct)\n",
    "    approx = np.asarray(approx)\n",
    "    absolute = np.mean(np.abs(correct - approx))\n",
    "    mean_abs_correct = np.mean(np.abs(correct))\n",
    "    if mean_abs_correct == 0:\n",
    "        return 0\n",
    "    relative = absolute / mean_abs_correct\n",
    "    return 1 - relative\n",
    "\n",
    "\n",
    "\n",
    "def softmax_contribuisci(x, index = 1):\n",
    "    if index == 1:\n",
    "        input_exp_1.append(torch.max(x).item())\n",
    "        input_exp_1.append(torch.min(x).item())\n",
    "    else:\n",
    "        input_exp_2.append(torch.max(x).item())\n",
    "        input_exp_2.append(torch.min(x).item())\n",
    "\n",
    "    for head in x.squeeze():\n",
    "        for row in head:\n",
    "            if index == 1:\n",
    "                input_inv_1.append(torch.sum(torch.exp(row)).item())\n",
    "            else:\n",
    "                input_inv_2.append(torch.sum(torch.exp(row)).item())\n",
    "\n",
    "    return torch.softmax(x, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b7bca88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:15<00:00, 26.39it/s]\n"
     ]
    }
   ],
   "source": [
    "input_exp_1 = []\n",
    "input_inv_1 = []\n",
    "input_gelu_1 = np.array([])\n",
    "input_exp_2 = []\n",
    "input_inv_2 = []\n",
    "input_gelu_2 = np.array([])\n",
    "input_tanh = np.array([])\n",
    "\n",
    "fhe_correct = 0\n",
    "fhe_wrong = 0\n",
    "\n",
    "fhe_accuracy = 0\n",
    "std_accuracy = 0\n",
    "\n",
    "for ind in tqdm(range(len(test_dataset))):\n",
    "    text = \"[CLS] \" + test_dataset['text'][ind] + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        \n",
    "    x = model.bert.embeddings(tokens_tensor, torch.tensor([[1] * len(tokenized_text)]))\n",
    "\n",
    "    key = model.bert.encoder.layer[0].attention.self.key.weight.clone().detach().double().transpose(0, 1)\n",
    "    query = model.bert.encoder.layer[0].attention.self.query.weight.clone().detach().double().transpose(0, 1)\n",
    "    value = model.bert.encoder.layer[0].attention.self.value.weight.clone().detach().double().transpose(0, 1)\n",
    "\n",
    "    key_bias = model.bert.encoder.layer[0].attention.self.key.bias.clone().detach().double()\n",
    "    query_bias = model.bert.encoder.layer[0].attention.self.query.bias.clone().detach().double()\n",
    "    value_bias = model.bert.encoder.layer[0].attention.self.value.bias.clone().detach().double()\n",
    "\n",
    "    original_input_tensor = x.double()\n",
    "\n",
    "    input_tensor = x.double()\n",
    "\n",
    "    q = torch.matmul(input_tensor, query) + query_bias\n",
    "    k = torch.matmul(input_tensor, key) + key_bias\n",
    "    v = torch.matmul(input_tensor, value) + value_bias\n",
    "\n",
    "    q = q.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    k = k.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    v = v.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "\n",
    "    q = q.permute([0, 2, 1, 3])\n",
    "    k = k.permute([0, 2, 3, 1])\n",
    "\n",
    "    qk = torch.matmul(q, k)\n",
    "    qk = qk / 8\n",
    "\n",
    "    qk_softmaxed = softmax_contribuisci(qk)\n",
    "\n",
    "    v = v.permute([0, 2, 1, 3])\n",
    "\n",
    "    fin = torch.matmul(qk_softmaxed, v)\n",
    "    fin = fin.permute([0, 2, 1, 3])\n",
    "    fin = fin.reshape([1, input_tensor.size()[1], 128])\n",
    "    \n",
    "    #mean = np.array([-0.03383045433490704, -0.04689138747464171, -0.04320052751297194, -0.04194874763842685, -0.03849735236740709, -0.03583471496309556, -0.036673685450259945, -0.03533623114666153, -0.03301200050649906, -0.03385619903604035, -0.03394064677150061, -0.03581378040060232, -0.04000193681582013, -0.042994980738727644, -0.042689484809151766, -0.0422699887342667, -0.040702211423783496, -0.043257636922742766, -0.040924377288572664, -0.04212762593354266, -0.040090620729304687, -0.03727317047412721, -0.030603299343800818, -0.034141189654495016, -0.03468711091296442, -0.032307857857310274, -0.02926372943560165, -0.031292906450152466, -0.037837883896213766, -0.03745859562807607, -0.03794657692710982, -0.03860214509229593, -0.036185650111238955, -0.039154371235979875, -0.03589729976884486, -0.031731895884233016, -0.03465287223481833, -0.031348414682812194, -0.03688161652969029, -0.03338290816163936, -0.038240660222183975, -0.037525466450406116, -0.038229222217722264, -0.041201914113547705, -0.04212576296359885, -0.03980083151775188, -0.04072657806877826, -0.040145599490268025, -0.036685242667777444, -0.034109016054392725, -0.03544325775104831, -0.03623692053970561, -0.04948334692050963, -0.04596823422981405, -0.04892271117435003])\n",
    "    #var = np.array([0.7495962428549272, 0.6109555428467895, 0.6225590467577651, 0.62495153067201, 0.631395549935461, 0.634492711694546, 0.644892789064359, 0.6542099965205022, 0.6595559062153842, 0.6659906881037033, 0.6680168012366937, 0.6758412527257586, 0.6668118068796066, 0.6718192460326265, 0.67786737736941, 0.6808577853930836, 0.6736657333151266, 0.6676446046843724, 0.6659979061989304, 0.6743226078654423, 0.681388263935704, 0.6837117808950258, 0.6907147768934253, 0.684537831509984, 0.6896744328697597, 0.6916627127801457, 0.6954043965468235, 0.6954046755145293, 0.7001025287354249, 0.695094327647078, 0.6854203403085795, 0.7027792682295838, 0.6956849098218769, 0.6945153573872891, 0.6856697060013522, 0.6897353511373785, 0.700668908202082, 0.6965624918742969, 0.7082690699456209, 0.7043163331126293, 0.7070770512949652, 0.7042510307314358, 0.6978925459183357, 0.7205035876616076, 0.6902461198740245, 0.686971254827903, 0.7028843270104062, 0.7032880792671149, 0.7057843340136714, 0.7104860015626775, 0.7321738164781159, 0.71095817492914, 0.7401485084476891, 0.7312957890728539, 0.7375994654874705])\n",
    "    mean = mean_0_0\n",
    "    var = inv_sqrt_var_0_0\n",
    "    \n",
    "    \n",
    "    w_output_dense = model.bert.encoder.layer[0].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[0].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + original_input_tensor\n",
    "\n",
    "    fin3_whole = []\n",
    "\n",
    "    for i in range(len(original_input_tensor.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "        fin3_corr = (fin2.squeeze().detach() - mean[i]) * var[i]\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[0].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr.detach())\n",
    "\n",
    "    fin3_whole = torch.cat(tuple(fin3_whole), 0).unsqueeze(0)\n",
    "    fin_4 = torch.matmul(fin3_whole, model.bert.encoder.layer[0].intermediate.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[0].intermediate.dense.bias\n",
    "\n",
    "    input_gelu_1 = np.append(input_gelu_1, fin_4.reshape(-1).detach().numpy())\n",
    "    \n",
    "    fin_5 = torch.nn.functional.gelu(fin_4)\n",
    "    fin_6 = torch.matmul(fin_5, model.bert.encoder.layer[0].output.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[0].output.dense.bias\n",
    "    fin_6 = fin_6 + fin3_whole\n",
    "    \n",
    "    #mean = np.array([-0.09545516102868973, 0.034540955180462664, 0.03934738149667437, 0.040802318439555035, 0.04426037798445811, 0.04919343175846099, 0.0493616301294401, 0.047896279398118795, 0.04912640635535303, 0.048717249992826256, 0.0477219385203478, 0.05095357678578503, 0.05094908370417657, 0.0493275745992752, 0.048418324664654545, 0.0473653504669205, 0.04528009986283869, 0.04524247257539856, 0.046555073355952846, 0.0516135997743503, 0.049103903254210594, 0.048877585502238356, 0.048364988370661784, 0.049043507301742846, 0.049933470462367846, 0.05175179126331398, 0.05057227793143223, 0.055763206569478994, 0.055243365455213404, 0.04986745821758072, 0.047789218698650125, 0.047852162700887234, 0.04279460740337753, 0.04280733225675328, 0.04644169155736491, 0.04783492130826333, 0.04759649093761958, 0.045252139153821, 0.04367184005341422, 0.039034762655413016, 0.04374965234639466, 0.04355128435775863, 0.04499861862695065, 0.04318602336450084, 0.04549296197766528, 0.03907804279518851, 0.037683132925437485, 0.04109696491189214, 0.04410155617431274, 0.05015992918511731, 0.04335430986396108, 0.046492484403760526, 0.044277581701870204, 0.03723061917091777, 0.039156973130334664])\n",
    "    #var = np.array([0.4156698594967092, 0.7008452266859936, 0.7214270983257646, 0.7095727482866087, 0.7102521835201318, 0.710293676073547, 0.7091783271698753, 0.6973493176419543, 0.7011688527520855, 0.7007704875343309, 0.6950537183089973, 0.6948029158092094, 0.6919309911197036, 0.6933694537037308, 0.6970711644923971, 0.7004276850010867, 0.6964234913676165, 0.6987678419874651, 0.6951829293138483, 0.6973048809142951, 0.6989420799277399, 0.7005696487948311, 0.6993937733493811, 0.6902070532566239, 0.6958399824203775, 0.6900361005407983, 0.6925891359742274, 0.6831642926666377, 0.6865279710039072, 0.6904370385593245, 0.6963724536275457, 0.6948942601360332, 0.6784634186071326, 0.6759657478656234, 0.6828578884489792, 0.683566347862741, 0.6857777074044566, 0.672040915409448, 0.6784995422914343, 0.6732453264186854, 0.683881765911935, 0.6909411690410042, 0.6715428435769978, 0.6775867807314924, 0.6785015863916147, 0.676156117696202, 0.6786376609996214, 0.6763771062984715, 0.7119440584663215, 0.7070342067744777, 0.6895996022331654, 0.6683970656272868, 0.6695013664908844, 0.6566575067124804, 0.672887703816164])\n",
    "    mean = mean_0_1\n",
    "    var = inv_sqrt_var_0_1\n",
    "    \n",
    "    fin7_whole = []\n",
    "\n",
    "    for i in range(len(input_tensor.squeeze())):\n",
    "        fin_7 = fin_6.squeeze()[i]\n",
    "\n",
    "        fin7_corr = (fin_7.squeeze().detach() - mean[i]) * var[i]\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[0].output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[0].output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin7_corr = fin7_corr * w_output_layernorm + b_output_layernorm\n",
    "\n",
    "        fin7_whole.append(fin7_corr.detach())\n",
    "\n",
    "    fin7_whole = torch.cat(tuple(fin7_whole), 0).unsqueeze(0)\n",
    "    \n",
    "    real = model.bert.encoder.layer[0](x)[0].transpose(1, 2).reshape(-1).detach()\n",
    "    \n",
    "    #print(\"Precision: {}\".format(precision(real, fin7_whole[0].transpose(0, 1).reshape(-1).detach())))\n",
    "    \n",
    "    key = model.bert.encoder.layer[1].attention.self.key.weight.clone().detach().double().transpose(0, 1)\n",
    "    query = model.bert.encoder.layer[1].attention.self.query.weight.clone().detach().double().transpose(0, 1)\n",
    "    value = model.bert.encoder.layer[1].attention.self.value.weight.clone().detach().double().transpose(0, 1)\n",
    "\n",
    "    key_bias = model.bert.encoder.layer[1].attention.self.key.bias.clone().detach().double()\n",
    "    query_bias = model.bert.encoder.layer[1].attention.self.query.bias.clone().detach().double()\n",
    "    value_bias = model.bert.encoder.layer[1].attention.self.value.bias.clone().detach().double()\n",
    "\n",
    "    original_input_tensor = fin7_whole\n",
    "    input_tensor = fin7_whole\n",
    "\n",
    "    q = torch.matmul(input_tensor, query) + query_bias\n",
    "    k = torch.matmul(input_tensor, key) + key_bias\n",
    "    v = torch.matmul(input_tensor, value) + value_bias\n",
    "\n",
    "    q = q.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    k = k.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "    v = v.reshape([1, input_tensor.size()[1], 2, 64])\n",
    "\n",
    "    q = q.permute([0, 2, 1, 3])\n",
    "    k = k.permute([0, 2, 3, 1])\n",
    "\n",
    "    qk = torch.matmul(q, k)\n",
    "    qk = qk / 8\n",
    "\n",
    "    qk_softmaxed = softmax_contribuisci(qk, 2)\n",
    "\n",
    "    v = v.permute([0, 2, 1, 3])\n",
    "\n",
    "    fin = torch.matmul(qk_softmaxed, v)\n",
    "    fin = fin.permute([0, 2, 1, 3])\n",
    "    fin = fin.reshape([1, input_tensor.size()[1], 128])\n",
    "    \n",
    "    #mean = np.array([0.04805131047475803, 0.014145706172069285, 0.010630181813540026, 0.010521146572975027, 0.00956244983947186, 0.008211288558782809, 0.008817800275674387, 0.008911457532306733, 0.008643898058317862, 0.008801769546523253, 0.009472254700839258, 0.008094415948174241, 0.007702615754430344, 0.005460620353838359, 0.007021847370084451, 0.008373831982472147, 0.01022061224155272, 0.00927594903773269, 0.009277225000069925, 0.007049453120897054, 0.008682554190420182, 0.008749022040809715, 0.010118317324741522, 0.008998865743435887, 0.008763833543884292, 0.008285728555981435, 0.006967351876718886, 0.00588068616144895, 0.0030701809065725363, 0.003659716972971551, 0.002116778487431024, 0.003947434346765913, 0.006907859825079262, 0.008494112860837831, 0.007040283968419036, 0.007197681884381672, 0.008232685835987293, 0.009965029801574864, 0.00731962961637719, 0.00830555309310382, 0.005340440177451385, 0.007833324368720607, 0.01047456825511633, 0.009674864773662995, 0.010093537461664302, 0.01588798917017868, 0.018537933333636507, 0.018245848282989877, 0.012253993810893607, 0.011354133953173591, 0.013474744814287221, 0.013707011955501919, 0.007918842609048385, 0.017240907760895086, 0.03465881962238184])\n",
    "    #var = np.array([0.6741653046411179, 0.602392389437227, 0.5945841451997256, 0.5997135932136959, 0.6033806506910513, 0.6064839949503851, 0.6058735285405447, 0.6059001754921257, 0.6086086189801689, 0.6118981975241923, 0.6161533101614306, 0.6105411757987637, 0.6102443339235957, 0.6004337682468068, 0.6068584434133084, 0.6123178593290803, 0.6150302868629213, 0.6102744641580546, 0.6143169356654037, 0.6105845722771672, 0.61540315154488, 0.622109065598561, 0.6221720668578823, 0.6279330579960701, 0.6282907135959079, 0.6258439179151315, 0.6187239026398644, 0.618294817104495, 0.609488586748927, 0.6085185174201381, 0.6154275326252285, 0.6207534846328591, 0.6290521066315713, 0.6375810334496135, 0.6238236165346044, 0.6310571465398529, 0.6350551779511981, 0.6452639043477173, 0.6346915398812409, 0.646622546259538, 0.6435498445423712, 0.6401589932559348, 0.6458833892517316, 0.6354378204804867, 0.651796667347259, 0.6547600574517144, 0.6554038815336571, 0.655910889886979, 0.6412602949793637, 0.6489736968517984, 0.6633309254993116, 0.6771441398382873, 0.6423362709438692, 0.6302863730404997, 0.5940213893371686])\n",
    "    mean = mean_1_0\n",
    "    var = inv_sqrt_var_1_0\n",
    "    \n",
    "    w_output_dense = model.bert.encoder.layer[1].attention.output.dense.weight.clone().detach().double().transpose(0, 1)\n",
    "    b_output_dense = model.bert.encoder.layer[1].attention.output.dense.bias.clone().detach().double()\n",
    "\n",
    "    fin2 = torch.matmul(fin, w_output_dense) + b_output_dense\n",
    "    fin2_backup = fin2.clone()\n",
    "    fin2_backup = fin2_backup + original_input_tensor\n",
    "\n",
    "    fin3_whole = []\n",
    "\n",
    "    for i in range(len(original_input_tensor.squeeze())):\n",
    "        fin2 = fin2_backup.squeeze()[i]\n",
    "\n",
    "        fin3_corr = (fin2.squeeze().detach() - mean[i]) * var[i]\n",
    "\n",
    "        #TODO QUA STO USANDO I VERI VALORI!!!!\n",
    "        #fin3_corr = (fin2.squeeze().detach() - torch.mean(fin2.squeeze())) / math.sqrt(torch.var(fin2.squeeze()))\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[1].attention.output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[1].attention.output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin3_corr = fin3_corr * w_output_layernorm + b_output_layernorm\n",
    "        fin3_whole.append(fin3_corr.detach())\n",
    "\n",
    "    fin3_whole = torch.cat(tuple(fin3_whole), 0).unsqueeze(0)\n",
    "    fin_4 = torch.matmul(fin3_whole, model.bert.encoder.layer[1].intermediate.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[1].intermediate.dense.bias\n",
    "\n",
    "    input_gelu_2 = np.append(input_gelu_2, fin_4.reshape(-1).detach().numpy())\n",
    "    \n",
    "    fin_5 = torch.nn.functional.gelu(fin_4)\n",
    "    \n",
    "    fin_6 = torch.matmul(fin_5, model.bert.encoder.layer[1].output.dense.weight.transpose(0, 1).double()) + model.bert.encoder.layer[1].output.dense.bias\n",
    "    fin_6 = fin_6 + fin3_whole\n",
    "    \n",
    "    fin7_whole = []\n",
    "    \n",
    "    mean = mean_1_1\n",
    "    var = inv_sqrt_var_1_1\n",
    "\n",
    "    for i in range(len(input_tensor.squeeze())):\n",
    "        fin_7 = fin_6.squeeze()[i]\n",
    "\n",
    "        fin7_corr = (fin_7.squeeze().detach() - mean[i]) * var[i]\n",
    "\n",
    "        w_output_layernorm = model.bert.encoder.layer[1].output.LayerNorm.weight.clone().detach().double().unsqueeze(0)\n",
    "        b_output_layernorm = model.bert.encoder.layer[1].output.LayerNorm.bias.clone().detach().double()\n",
    "\n",
    "        fin7_corr = fin7_corr * w_output_layernorm + b_output_layernorm\n",
    "\n",
    "        fin7_whole.append(fin7_corr.detach())\n",
    "\n",
    "    fin7_whole = torch.cat(tuple(fin7_whole), 0).unsqueeze(0)\n",
    "\n",
    "    real = model.bert.encoder.layer[1](model.bert.encoder.layer[0](x)[0])[0].transpose(1, 2).reshape(-1).detach()\n",
    "    correct = fin7_whole[0].transpose(0, 1).reshape(-1).detach()\n",
    "\n",
    "    input_tanh = np.append(input_tanh, (torch.matmul(fin7_whole.double(), model.bert.pooler.dense.weight.transpose(0, 1).double()) + model.bert.pooler.dense.bias).reshape(-1).detach())\n",
    "    \n",
    "    #print(\"Precision: {}\".format(precision(real, correct)))\n",
    "    densed_pooler = torch.tanh(torch.matmul(fin7_whole.double(), model.bert.pooler.dense.weight.transpose(0, 1).double()) + model.bert.pooler.dense.bias)\n",
    "\n",
    "    approx = densed_pooler[0][0].detach()\n",
    "    precise = model.bert.pooler(model.bert.encoder(x)[0]).detach()[0]\n",
    "\n",
    "    #print(precision(precise, approx))\n",
    "    \n",
    "    output = torch.matmul(approx, model.classifier.weight.transpose(0, 1).double()) + model.classifier.bias.double()\n",
    "    output_real = model(tokens_tensor, torch.tensor([[1] * len(tokenized_text)])).logits[0].detach()\n",
    "    \n",
    "    # Multi-labels\n",
    "    predicted = torch.argmax(output).item()\n",
    "    predicted_real = torch.argmax(output_real).item()\n",
    "\n",
    "    if predicted == test_dataset['label'][ind]:\n",
    "      fhe_accuracy += 1\n",
    "\n",
    "    if predicted_real == test_dataset['label'][ind]:\n",
    "      fhe_correct += 1\n",
    "    else:\n",
    "      fhe_wrong += 1\n",
    "\n",
    "    if predicted_real == test_dataset['label'][ind]:\n",
    "      std_accuracy += 1\n",
    "    \n",
    "    \"\"\"\n",
    "    if output[0].item() > output[1].item() and output_real[0].item() > output_real[1].item():\n",
    "        fhe_correct = fhe_correct + 1\n",
    "    elif output[0].item() < output[1].item() and output_real[0].item() < output_real[1].item():\n",
    "        fhe_correct = fhe_correct + 1\n",
    "    else:\n",
    "        fhe_wrong = fhe_wrong + 1\n",
    "        \n",
    "    if output[0].item() > output[1].item() and valid_dataset['label'][ind] == 0:\n",
    "        fhe_accuracy = fhe_accuracy + 1\n",
    "    if output[0].item() < output[1].item() and valid_dataset['label'][ind] == 1:\n",
    "        fhe_accuracy = fhe_accuracy + 1\n",
    "        \n",
    "    if output_real[0].item() > output_real[1].item() and valid_dataset['label'][ind] == 0:\n",
    "        std_accuracy = std_accuracy + 1\n",
    "    if output_real[0].item() < output_real[1].item() and valid_dataset['label'][ind] == 1:\n",
    "        std_accuracy = std_accuracy + 1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a8f5ec78-a7f2-4183-a964-bd1bd5af6e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard model accuracy:    0.902\n",
      "Precomputed model accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard model accuracy:    {}\\nPrecomputed model accuracy: {}\".format(std_accuracy / len(valid_dataset), fhe_accuracy / len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b1cf6d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.446025791624114\n",
      "13601.695105095436\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Encoder 1 - Inverse 1/x\")\n",
    "plt.plot(input_inv_1)\n",
    "print(min(input_inv_1))\n",
    "print(max(input_inv_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c4f074c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.277488820516531\n",
      "13.582576585824105\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Encoder 1 - GELU\")\n",
    "input_gelu_1 = np.array(input_gelu_1).reshape(-1)\n",
    "#plt.plot(input_gelu_1)\n",
    "print(min(input_gelu_1))\n",
    "print(max(input_gelu_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e5e406ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New interval for inverse function in Encoder 2: [0.13023906832660034, 386200]\n",
      "Optimal degree for clamped interval: 404\n"
     ]
    }
   ],
   "source": [
    "# Clamp values to remove extreme outliers\n",
    "def clamp(x, min_val, max_val):\n",
    "    return max(min(x, max_val), min_val)\n",
    "\n",
    "clamped_input_inv_2 = [clamp(x, 0.1, 386200) for x in input_inv_2]\n",
    "\n",
    "# Recalculate interval\n",
    "interval_inv_2 = [min(clamped_input_inv_2), max(clamped_input_inv_2)]\n",
    "\n",
    "print(f\"New interval for inverse function in Encoder 2: {interval_inv_2}\")\n",
    "\n",
    "# Rerun the polynomial approximation with the new interval\n",
    "optimal_degree_inv_2, degrees_inv, max_errors_inv, mean_errors_inv = find_optimal_degree(\n",
    "    func_inv, interval_inv_2, max_degree=500, desired_max_error=0.001, num_points=10000\n",
    ")\n",
    "\n",
    "print(f\"Optimal degree for clamped interval: {optimal_degree_inv_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4c1cc314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal degree for 1/x: 326\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_degree(func, interval, max_degree, desired_max_error, num_points, step=1):\n",
    "    x_min, x_max = interval\n",
    "    degrees = list(range(1, max_degree + 1, step))\n",
    "    x_dense = np.linspace(x_min, x_max, num_points)\n",
    "    y_true = func(x_dense)\n",
    "    \n",
    "    for degree in degrees:\n",
    "        cheb = Chebyshev.fit(x_dense, y_true, deg=degree)\n",
    "        y_approx = cheb(x_dense)\n",
    "        max_error = np.max(np.abs(y_true - y_approx))\n",
    "        \n",
    "        if max_error <= desired_max_error:\n",
    "            return degree\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage:\n",
    "interval_inv_1 = [0.1, 3000]\n",
    "optimal_degree_inv_1 = find_optimal_degree(\n",
    "    func_inv, interval_inv_1, max_degree=500, \n",
    "    desired_max_error=0.01, num_points=10000, step=5\n",
    ")\n",
    "print(f\"Optimal degree for 1/x: {optimal_degree_inv_1}\")\n",
    "\n",
    "# Repeat for other functions and intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c519392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_percentiles(data, percentiles):\n",
    "    return np.percentile(data, percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a45c00c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th percentile: 0.13023906832660034\n",
      "0.1th percentile: 6.284662783004165\n",
      "1th percentile: 40.29194176171038\n",
      "5th percentile: 127.51080927934203\n",
      "10th percentile: 284.10642904907763\n",
      "25th percentile: 2417.8568174955717\n",
      "50th percentile: 16103.160149176158\n",
      "75th percentile: 177492.90045678653\n",
      "80th percentile: 386153.9287089441\n",
      "85th percentile: 1080671.5149485397\n",
      "90th percentile: 5149230.44558018\n",
      "95th percentile: 97097680.84275296\n",
      "99th percentile: 103741600460.81895\n",
      "99.9th percentile: 225939505273269.4\n",
      "100th percentile: 3.521431747848244e+21\n",
      "Values above 1000.0: 73587 (82.8235%)\n",
      "Values above 380000.0: 17865 (20.1074%)\n",
      "Values above 1000000.0: 13592 (15.2980%)\n",
      "Values above 1000000000.0: 2700 (3.0389%)\n",
      "Values above 1000000000000.0: 470 (0.5290%)\n",
      "Values above 1000000000000000.0: 61 (0.0687%)\n",
      "Values above 1e+18: 12 (0.0135%)\n",
      "Values above 1e+21: 1 (0.0011%)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array for easier manipulation\n",
    "input_inv_2_array = np.array(input_inv_2)\n",
    "\n",
    "# Calculate percentiles\n",
    "percentiles = [0, 0.1, 1, 5, 10, 25, 50, 75, 80, 85,90, 95, 99, 99.9, 100]\n",
    "percentile_values = calculate_percentiles(input_inv_2_array, percentiles)\n",
    "\n",
    "# Print results\n",
    "for p, v in zip(percentiles, percentile_values):\n",
    "    print(f\"{p}th percentile: {v}\")\n",
    "\n",
    "# Count how many values are above certain thresholds\n",
    "thresholds = [1e3, 3.8e5, 1e6, 1e9, 1e12, 1e15, 1e18, 1e21]\n",
    "for t in thresholds:\n",
    "    count = np.sum(input_inv_2_array > t)\n",
    "    percentage = (count / len(input_inv_2_array)) * 100\n",
    "    print(f\"Values above {t}: {count} ({percentage:.4f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7c50509e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13023906832660034\n",
      "3.521431747848244e+21\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Encoder 2 - Inverse 1/x\")\n",
    "plt.plot(input_inv_2)\n",
    "print(min(input_inv_2))\n",
    "print(max(input_inv_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dc89186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.89314080733233\n",
      "33.714340291536836\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Encoder 2 - GELU\")\n",
    "input_gelu_1 = np.array(input_gelu_2).reshape(-1)\n",
    "print(min(input_gelu_2))\n",
    "print(max(input_gelu_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c63c9acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-71.04789330781173\n",
      "67.3809725302385\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Pooler - Tanh\")\n",
    "print(min(input_tanh))\n",
    "print(max(input_tanh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5efa4b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Error: 4.702089167234885e-05\n",
      "Mean Error: 1.590720918747662e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial import Chebyshev\n",
    "\n",
    "def test_polynomial_approximation(func, interval, degree, num_points=1000):\n",
    "    x = np.linspace(interval[0], interval[1], num_points)\n",
    "    y_true = func(x)\n",
    "    cheb = Chebyshev.fit(x, y_true, deg=degree)\n",
    "    y_approx = cheb(x)\n",
    "    error = np.abs(y_true - y_approx)\n",
    "    max_error = np.max(error)\n",
    "    mean_error = np.mean(error)\n",
    "    return max_error, mean_error, cheb\n",
    "\n",
    "# Example for 1/x over [3, 13500] with degree 119\n",
    "max_error, mean_error, cheb = test_polynomial_approximation(func_inv, [2, 5000], 119)\n",
    "\n",
    "print(f\"Max Error: {max_error}\")\n",
    "print(f\"Mean Error: {mean_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6e12065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions to approximate\n",
    "def func_inv(x):\n",
    "    return 1 / x\n",
    "\n",
    "def func_gelu(x):\n",
    "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n",
    "\n",
    "def func_tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Define the approximation intervals\n",
    "# sst2\n",
    "interval_inv_1 = [2, 5000] # degree 119\n",
    "interval_inv_2 = [3, 1300000] # degree 200\n",
    "interval_gelu_1 = [-14, 11] # degree 119\n",
    "interval_gelu_2 = [-18, 8] # degree 59\n",
    "interval_tanh = [-20, 20] # degree 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "335fba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.polynomial import Chebyshev\n",
    "\n",
    "def find_optimal_degree(func, interval, max_degree, desired_max_error, num_points):\n",
    "    \"\"\"\n",
    "    Determines the optimal degree of a Chebyshev polynomial to approximate a given function within a specified error.\n",
    "\n",
    "    Parameters:\n",
    "    - func: The function to approximate.\n",
    "    - interval: A list or tuple specifying the [min, max] interval for approximation.\n",
    "    - max_degree: The maximum degree of polynomials to test.\n",
    "    - desired_max_error: The maximum acceptable error.\n",
    "    - num_points: Number of points to evaluate the approximation.\n",
    "\n",
    "    Returns:\n",
    "    - optimal_degree: The smallest degree that achieves the desired_max_error.\n",
    "    - degrees: List of degrees tested.\n",
    "    - max_errors: Corresponding maximum errors for each degree.\n",
    "    - mean_errors: Corresponding mean errors for each degree.\n",
    "    \"\"\"\n",
    "    x_min, x_max = interval\n",
    "    degrees = list(range(1, max_degree + 1))\n",
    "    max_errors = []\n",
    "    mean_errors = []\n",
    "    x_dense = np.linspace(x_min, x_max, num_points)\n",
    "    y_true = func(x_dense)\n",
    "    \n",
    "    for degree in degrees:\n",
    "        # Fit Chebyshev polynomial\n",
    "        cheb = Chebyshev.fit(x_dense, y_true, deg=degree)\n",
    "        \n",
    "        # Evaluate the polynomial\n",
    "        y_approx = cheb(x_dense)\n",
    "        \n",
    "        # Calculate errors\n",
    "        errors = np.abs(y_true - y_approx)\n",
    "        max_error = np.max(errors)\n",
    "        mean_error = np.mean(errors)\n",
    "        \n",
    "        # Store errors\n",
    "        max_errors.append(max_error)\n",
    "        mean_errors.append(mean_error)\n",
    "        \n",
    "        #print(f\"Degree: {degree}, Max Error: {max_error:.6f}, Mean Error: {mean_error:.6f}\")\n",
    "    \n",
    "    # Identify the smallest degree that meets the desired max error\n",
    "    suitable_degrees = [deg for deg, err in zip(degrees, max_errors) if err <= desired_max_error]\n",
    "    \n",
    "    if suitable_degrees:\n",
    "        optimal_degree = suitable_degrees[0]\n",
    "        #print(f\"\\nOptimal Degree for Max Error <= {desired_max_error}: {optimal_degree}\")\n",
    "    else:\n",
    "        optimal_degree = None\n",
    "        #print(\"\\nDesired accuracy not achieved within the tested degrees.\")\n",
    "    \n",
    "    return optimal_degree, degrees, max_errors, mean_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6142fa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximating 1/x over [2, 5000]:\n",
      "Approximating 1/x over [3, 130000]:\n",
      "\n",
      "Approximating GELU over [-14, 11]:\n",
      "\n",
      "Approximating GELU over [-18, 8]:\n",
      "\n",
      "Approximating tanh over [-20, 20]:\n"
     ]
    }
   ],
   "source": [
    "# Determine degree for 1/x\n",
    "print(\"Approximating 1/x over [2, 5000]:\")\n",
    "optimal_degree_inv_1, degrees_inv, max_errors_inv, mean_errors_inv = find_optimal_degree(\n",
    "    func_inv, interval_inv_1, max_degree=500, desired_max_error=0.01, num_points=5000\n",
    ")\n",
    "\n",
    "print(\"Approximating 1/x over [3, 130000]:\")\n",
    "optimal_degree_inv_2, degrees_inv, max_errors_inv, mean_errors_inv = find_optimal_degree(\n",
    "    func_inv, interval_inv_2, max_degree=500, desired_max_error=0.001, num_points=4000\n",
    ")\n",
    "\n",
    "# Determine degree for GELU\n",
    "print(\"\\nApproximating GELU over [-14, 11]:\")\n",
    "optimal_degree_gelu_1, degrees_gelu, max_errors_gelu, mean_errors_gelu = find_optimal_degree(\n",
    "    func_gelu, interval_gelu_1, max_degree=500, desired_max_error=0.000000001, num_points=5000\n",
    ")\n",
    "print(\"\\nApproximating GELU over [-18, 8]:\")\n",
    "optimal_degree_gelu_2, degrees_gelu, max_errors_gelu, mean_errors_gelu = find_optimal_degree(\n",
    "    func_gelu, interval_gelu_2, max_degree=500, desired_max_error=0.000001, num_points=5000\n",
    ")\n",
    "\n",
    "# Determine degree for tanh\n",
    "print(\"\\nApproximating tanh over [-20, 20]:\")\n",
    "optimal_degree_tanh, degrees_tanh, max_errors_tanh, mean_errors_tanh = find_optimal_degree(\n",
    "    func_tanh, interval_tanh, max_degree=500, desired_max_error=0.000000001, num_points=20000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3563d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "201\n",
      "103\n",
      "65\n",
      "267\n"
     ]
    }
   ],
   "source": [
    "print(optimal_degree_inv_1)\n",
    "print(optimal_degree_inv_2)\n",
    "\n",
    "print(optimal_degree_gelu_1)\n",
    "print(optimal_degree_gelu_2)\n",
    "\n",
    "print(optimal_degree_tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093fe9a",
   "metadata": {},
   "source": [
    "Apply for emotion classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "05359841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions to approximate\n",
    "def func_inv(x):\n",
    "    return 1 / x\n",
    "\n",
    "def func_gelu(x):\n",
    "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n",
    "\n",
    "def func_tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Define the approximation intervals\n",
    "# sst2\n",
    "interval_inv_1 = [3, 13500] # degree 119\n",
    "interval_inv_2 = [0.001, 386153] # degree 200\n",
    "interval_gelu_1 = [-13.5, 13.5] # degree 119\n",
    "interval_gelu_2 = [-33.5, 33.5] # degree 59\n",
    "interval_tanh = [-71, 67] # degree 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2a56f418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximating 1/x over [2, 5000]:\n",
      "Approximating 1/x over [3, 130000]:\n",
      "\n",
      "Approximating GELU over [-14, 11]:\n",
      "\n",
      "Approximating GELU over [-18, 8]:\n",
      "\n",
      "Approximating tanh over [-20, 20]:\n",
      "196\n",
      "None\n",
      "44\n",
      "102\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "# Determine degree for 1/x\n",
    "print(\"Approximating 1/x over [2, 5000]:\")\n",
    "optimal_degree_inv_1, degrees_inv, max_errors_inv, mean_errors_inv = find_optimal_degree(\n",
    "    func_inv, interval_inv_1, max_degree=500, desired_max_error=0.001, num_points=10000\n",
    ")\n",
    "\n",
    "print(\"Approximating 1/x over [3, 130000]:\")\n",
    "optimal_degree_inv_2, degrees_inv, max_errors_inv, mean_errors_inv = find_optimal_degree(\n",
    "    func_inv, interval_inv_2, max_degree=500, desired_max_error=0.001, num_points=10000\n",
    ")\n",
    "\n",
    "# Determine degree for GELU\n",
    "print(\"\\nApproximating GELU over [-14, 11]:\")\n",
    "optimal_degree_gelu_1, degrees_gelu, max_errors_gelu, mean_errors_gelu = find_optimal_degree(\n",
    "    func_gelu, interval_gelu_1, max_degree=500, desired_max_error=0.001, num_points=5000\n",
    ")\n",
    "print(\"\\nApproximating GELU over [-18, 8]:\")\n",
    "optimal_degree_gelu_2, degrees_gelu, max_errors_gelu, mean_errors_gelu = find_optimal_degree(\n",
    "    func_gelu, interval_gelu_2, max_degree=500, desired_max_error=0.001, num_points=5000\n",
    ")\n",
    "\n",
    "# Determine degree for tanh\n",
    "print(\"\\nApproximating tanh over [-20, 20]:\")\n",
    "optimal_degree_tanh, degrees_tanh, max_errors_tanh, mean_errors_tanh = find_optimal_degree(\n",
    "    func_tanh, interval_tanh, max_degree=500, desired_max_error=0.001, num_points=20000\n",
    ")\n",
    "\n",
    "print(optimal_degree_inv_1)\n",
    "print(optimal_degree_inv_2)\n",
    "\n",
    "print(optimal_degree_gelu_1)\n",
    "print(optimal_degree_gelu_2)\n",
    "\n",
    "print(optimal_degree_tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00cf89",
   "metadata": {},
   "source": [
    "# Check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
