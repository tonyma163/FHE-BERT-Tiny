{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/3t/qv8zrd4d5t12dqxjq4rxf56r0000gn/T/ipykernel_68915/3930920598.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  trained = torch.load('./notebooks/SST-2-BERT-tiny.bin', map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Load fine-tuned model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "\n",
    "trained = torch.load('./notebooks/SST-2-BERT-tiny.bin', map_location=torch.device(\"cpu\"))\n",
    "trained.pop('bert.embeddings.position_ids', None) # Remove unexpected keys\n",
    "model.load_state_dict(trained , strict=True)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65536/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03560466319322586\n",
      "-0.03560466319322586\n"
     ]
    }
   ],
   "source": [
    "print(layer0_intermediate_weight[-2])\n",
    "print(layer0_intermediate_weight4[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "if 0.09879531 in layer0_intermediate_weight:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2465, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.encoder.layer[0].intermediate.dense.weight.transpose(0, 1)[31][511]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1565, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.encoder.layer[0].intermediate.dense.weight.transpose(0, 1)[127][511]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0_intermediate_weight = model.bert.encoder.layer[0].intermediate.dense.weight.transpose(0, 1).double().detach().numpy()\n",
    "layer1_intermediate_weight = model.bert.encoder.layer[1].intermediate.dense.weight.transpose(0, 1).double().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0_output_weight = model.bert.encoder.layer[0].output.dense.weight.transpose(0, 1).double().detach().numpy()\n",
    "layer1_output_weight = model.bert.encoder.layer[1].output.dense.weight.transpose(0, 1).double().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer0_intermediate_weight[0])*len(layer0_intermediate_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.87953097e-02  3.80718447e-02  2.70095393e-02 ...  1.55190434e-02\n",
      "  -4.06939769e-03  2.84967363e-01]\n",
      " [ 2.60726884e-02  5.67517877e-02 -2.42611510e-04 ... -2.85039637e-02\n",
      "   3.91533189e-02 -1.56141698e-01]\n",
      " [ 6.57312619e-03  9.66107659e-03  7.95733277e-03 ... -3.60841379e-02\n",
      "   3.38025503e-02  1.83659047e-01]\n",
      " [-4.64717075e-02 -1.24046348e-01 -4.05563377e-02 ...  5.58397286e-02\n",
      "  -8.19457620e-02  6.64943233e-02]\n",
      " [-2.24055313e-02 -7.50428289e-02  1.97503995e-02 ... -1.78632364e-01\n",
      "   6.18782192e-02  4.11385410e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(layer0_intermediate_weight[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat\n",
      "Saved bert.encoder.layer.0.attention.self.query.weight to new-weights-sst2/layer0_attself_query_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.0.attention.self.query.bias to new-weights-sst2/layer0_attself_query_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.0.attention.self.key.weight to new-weights-sst2/layer0_attself_key_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.0.attention.self.key.bias to new-weights-sst2/layer0_attself_key_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.0.attention.self.value.weight to new-weights-sst2/layer0_attself_value_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.0.attention.self.value.bias to new-weights-sst2/layer0_attself_value_bias.txt\n",
      "flat-F\n",
      "Saved bert.encoder.layer.0.attention.output.dense.weight to new-weights-sst2/layer0_selfoutput_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.0.attention.output.dense.bias to new-weights-sst2/layer0_selfoutput_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.0.intermediate.dense.weight to new-weights-sst2/layer0_intermediate_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.0.intermediate.dense.bias to new-weights-sst2/layer0_intermediate_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.0.output.dense.weight to new-weights-sst2/layer0_output_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.0.output.dense.bias to new-weights-sst2/layer0_output_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.1.attention.self.query.weight to new-weights-sst2/layer1_attself_query_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.1.attention.self.query.bias to new-weights-sst2/layer1_attself_query_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.1.attention.self.key.weight to new-weights-sst2/layer1_attself_key_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.1.attention.self.key.bias to new-weights-sst2/layer1_attself_key_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.1.attention.self.value.weight to new-weights-sst2/layer1_attself_value_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.1.attention.self.value.bias to new-weights-sst2/layer1_attself_value_bias.txt\n",
      "flat-F\n",
      "Saved bert.encoder.layer.1.attention.output.dense.weight to new-weights-sst2/layer1_selfoutput_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.1.attention.output.dense.bias to new-weights-sst2/layer1_selfoutput_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.1.intermediate.dense.weight to new-weights-sst2/layer1_intermediate_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.1.intermediate.dense.bias to new-weights-sst2/layer1_intermediate_bias.txt\n",
      "flat\n",
      "Saved bert.encoder.layer.1.output.dense.weight to new-weights-sst2/layer1_output_weight.txt\n",
      "origin\n",
      "Saved bert.encoder.layer.1.output.dense.bias to new-weights-sst2/layer1_output_bias.txt\n",
      "flat\n",
      "Saved bert.pooler.dense.weight to new-weights-sst2/pooler_dense_weight.txt\n",
      "origin\n",
      "Saved bert.pooler.dense.bias to new-weights-sst2/pooler_dense_bias.txt\n",
      "origin\n",
      "Saved classifier.weight to new-weights-sst2/classifier_weight.txt\n",
      "origin\n",
      "Saved classifier.bias to new-weights-sst2/classifier_bias.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create a directory to save the parameters\n",
    "os.makedirs('new-weights-sst2', exist_ok=True)\n",
    "\n",
    "# Access the state dictionary of the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Function to save a tensor to a text file\n",
    "def save_tensor_to_txt_flat(tensor, filepath):\n",
    "    print(\"flat\")\n",
    "    # Convert tensor to numpy array\n",
    "    array = tensor.cpu().detach().numpy()\n",
    "    \n",
    "    # Flatten the array in column-major (Fortran-style) order\n",
    "    flattened = array.T.flatten()\n",
    "    \n",
    "    # Calculate how many full rows of 128 elements we can make\n",
    "    num_full_rows = len(flattened) // 128\n",
    "    \n",
    "    # Reshape the array to have 128 columns, dropping any extra elements\n",
    "    reshaped_array = flattened[:num_full_rows * 128].reshape(-1, 128)\n",
    "    \n",
    "    # Save to text file with 128 values per line\n",
    "    np.savetxt(filepath, reshaped_array, delimiter=',')\n",
    "    \n",
    "    # If there are any remaining elements, save them on a final line\n",
    "    remaining = flattened[num_full_rows * 128:]\n",
    "    if len(remaining) > 0:\n",
    "        with open(filepath, 'a') as f:\n",
    "            np.savetxt(f, remaining.reshape(1, -1), delimiter=',')\n",
    "# Selfoutput\n",
    "def save_tensor_to_txt_flat_F(tensor, filepath):\n",
    "    print(\"flat-F\")\n",
    "    # Convert tensor to numpy array\n",
    "    array = tensor.cpu().detach().numpy()\n",
    "    \n",
    "    # Flatten the array in column-major (Fortran-style) order\n",
    "    flattened = array.T.flatten('F')\n",
    "    \n",
    "    # Calculate how many full rows of 128 elements we can make\n",
    "    num_full_rows = len(flattened) // 128\n",
    "    \n",
    "    # Reshape the array to have 128 columns, dropping any extra elements\n",
    "    reshaped_array = flattened[:num_full_rows * 128].reshape(-1, 128)\n",
    "    \n",
    "    # Save to text file with 128 values per line\n",
    "    np.savetxt(filepath, reshaped_array, delimiter=',')\n",
    "    \n",
    "    # If there are any remaining elements, save them on a final line\n",
    "    remaining = flattened[num_full_rows * 128:]\n",
    "    if len(remaining) > 0:\n",
    "        with open(filepath, 'a') as f:\n",
    "            np.savetxt(f, remaining.reshape(1, -1), delimiter=',')\n",
    "def save_tensor_to_txt(tensor, filepath):\n",
    "    print(\"origin\")\n",
    "    # Convert tensor to numpy array\n",
    "    array = tensor.cpu().numpy()\n",
    "    # Save to text file with desired formatting\n",
    "    with open(filepath, 'w') as f:\n",
    "        for row in array.reshape(-1):\n",
    "            f.write(f\"{row}\\n\")\n",
    "    #np.savetxt(filepath, array, delimiter=',')\n",
    "            \n",
    "# Function to save a tensor to a text file\n",
    "def save_tensor_to_txt2(tensor, filepath):\n",
    "    print(\"intermediate/output\")\n",
    "    # Convert tensor to numpy array\n",
    "    array = tensor.cpu().numpy()\n",
    "    # Reshape the array to 128 rows and 128 columns\n",
    "    reshaped_array = array.reshape(128, 128)\n",
    "    # Save to text file with desired formatting\n",
    "    np.savetxt(filepath, reshaped_array, delimiter=',')\n",
    "\n",
    "exclude_keywords = [\n",
    "    \"attself_query_weight\",\n",
    "    \"attself_key_weight\",\n",
    "    \"attself_value_weight\",\n",
    "    \"selfoutput_weight\",\n",
    "    \"pooler_dense_weight\",\n",
    "]\n",
    "    \n",
    "# Iterate through all parameters and save the ones you're interested in\n",
    "for name, param in state_dict.items():\n",
    "    # Check if the parameter name matches the desired layers\n",
    "    if any(keyword in name for keyword in [\n",
    "        'attention.self.query', \n",
    "        'attention.self.key', \n",
    "        'attention.self.value',\n",
    "        'attention.output.dense',\n",
    "        'intermediate.dense',\n",
    "        'output.dense',\n",
    "        'pooler.dense',\n",
    "        'classifier'\n",
    "    ]):\n",
    "        # Replace dots with underscores for file naming\n",
    "        filename = name.replace('.', '_') + '.txt'\n",
    "        \n",
    "        # remove bert_encoder_\n",
    "        if filename[:13] == \"bert_encoder_\":\n",
    "            filename = filename[13:]\n",
    "        elif filename[:5] == \"bert_\":\n",
    "            filename = filename[5:]\n",
    "            \n",
    "        # layer_0 -> layer0\n",
    "        filename = filename.replace('layer_0', 'layer0')\n",
    "        filename = filename.replace('layer_1', 'layer1')\n",
    "        \n",
    "        # attention_self -> attself\n",
    "        # attention_output_dense -> selfoutput\n",
    "        # intermediate_dense -> intermediate\n",
    "        # output_dense -> output\n",
    "        filename = filename.replace('attention_self', 'attself')\n",
    "        filename = filename.replace('attention_output_dense', 'selfoutput')\n",
    "        filename = filename.replace('intermediate_dense', 'intermediate')\n",
    "        filename = filename.replace('output_dense', 'output')\n",
    "        \n",
    "        filepath = os.path.join('new-weights-sst2', filename)\n",
    "        \n",
    "        if any(keyword in filepath for keyword in exclude_keywords):\n",
    "            if \"selfoutput\" in filepath:\n",
    "                save_tensor_to_txt_flat_F(param, filepath)\n",
    "            elif \"weight\" in filepath:\n",
    "                save_tensor_to_txt_flat(param, filepath)\n",
    "            else:\n",
    "                save_tensor_to_txt2(param, filepath)\n",
    "        elif \"intermediate_weight\" in filepath or \"output_weight\" in filepath:\n",
    "            save_tensor_to_txt_flat(param, filepath)\n",
    "        else:\n",
    "            save_tensor_to_txt(param, filepath)\n",
    "        print(f\"Saved {name} to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer0_intermediate_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlayer0_intermediate_weight\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "len(layer0_intermediate_weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "layer0_intermediate_weight = np.loadtxt(f\"./new-weights-sst2/layer0_intermediate_weight.txt\", delimiter=\",\")\n",
    "layer1_intermediate_weight = np.loadtxt(f\"./new-weights-sst2/layer1_intermediate_weight.txt\", delimiter=\",\")\n",
    "\n",
    "layer0_output_weight = np.loadtxt(f\"./new-weights-sst2/layer0_output_weight.txt\", delimiter=\",\")\n",
    "layer1_output_weight = np.loadtxt(f\"./new-weights-sst2/layer1_output_weight.txt\", delimiter=\",\")\n",
    "\n",
    "# Reshape the matrices into single columns\n",
    "layer0_intermediate_weight = layer0_intermediate_weight.flatten(order='C')\n",
    "layer1_intermediate_weight = layer1_intermediate_weight.flatten(order='C')\n",
    "layer0_output_weight = layer0_output_weight.flatten(order='C')\n",
    "layer1_output_weight = layer1_output_weight.flatten(order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = len(layer0_intermediate_weight)//4\n",
    "num = int(split_size)\n",
    "\n",
    "layer0_intermediate_weight1 = layer0_intermediate_weight[:num]\n",
    "layer0_intermediate_weight2 = layer0_intermediate_weight[num:(num*2)]\n",
    "layer0_intermediate_weight3 = layer0_intermediate_weight[(num*2):(num*3)]\n",
    "layer0_intermediate_weight4 = layer0_intermediate_weight[(num*3):(num*4)]\n",
    "layer1_intermediate_weight1 = layer1_intermediate_weight[:num]\n",
    "layer1_intermediate_weight2 = layer1_intermediate_weight[num:(num*2)]\n",
    "layer1_intermediate_weight3 = layer1_intermediate_weight[(num*2):(num*3)]\n",
    "layer1_intermediate_weight4 = layer1_intermediate_weight[(num*3):(num*4)]\n",
    "\n",
    "layer0_output_weight1 = layer0_output_weight[:num]\n",
    "layer0_output_weight2 = layer0_output_weight[num:(num*2)]\n",
    "layer0_output_weight3 = layer0_output_weight[(num*2):(num*3)]\n",
    "layer0_output_weight4 = layer0_output_weight[(num*3):(num*4)]\n",
    "layer1_output_weight1 = layer1_output_weight[:num]\n",
    "layer1_output_weight2 = layer1_output_weight[num:(num*2)]\n",
    "layer1_output_weight3 = layer1_output_weight[(num*2):(num*3)]\n",
    "layer1_output_weight4 = layer1_output_weight[(num*3):(num*4)]\n",
    "\n",
    "np.savetxt(\"./new-weights-sst2/layer0_intermediate_weight1.txt\", layer0_intermediate_weight1, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer0_intermediate_weight2.txt\", layer0_intermediate_weight2, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer0_intermediate_weight3.txt\", layer0_intermediate_weight3, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer0_intermediate_weight4.txt\", layer0_intermediate_weight4, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer1_intermediate_weight1.txt\", layer1_intermediate_weight1, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer1_intermediate_weight2.txt\", layer1_intermediate_weight2, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer1_intermediate_weight3.txt\", layer1_intermediate_weight3, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer1_intermediate_weight4.txt\", layer1_intermediate_weight4, delimiter=\",\")\n",
    "\n",
    "np.savetxt(\"./new-weights-sst2/layer0_output_weight1.txt\", layer0_output_weight1, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer0_output_weight2.txt\", layer0_output_weight2, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer0_output_weight3.txt\", layer0_output_weight3, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer0_output_weight4.txt\", layer0_output_weight4, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer1_output_weight1.txt\", layer1_output_weight1, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer1_output_weight2.txt\", layer1_output_weight2, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer1_output_weight3.txt\", layer1_output_weight3, delimiter=\",\")\n",
    "np.savetxt(\"./new-weights-sst2/layer1_output_weight4.txt\", layer1_output_weight4, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.loadtxt(\"./new-weights-sst2/layer0_intermediate_weight1.txt\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"./new-weights-sst2/layer0_intermediate_weight.txt\")\n",
    "os.remove(\"./new-weights-sst2/layer1_intermediate_weight.txt\")\n",
    "\n",
    "os.remove(\"./new-weights-sst2/layer0_output_weight.txt\")\n",
    "os.remove(\"./new-weights-sst2/layer1_output_weight.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weight (first 5): [0.09879531 0.03807184 0.02700954 0.03793886 0.01012474]\n",
      "Model weight (first 5): [ 0.09879531  0.02607269  0.00657313 -0.04647171 -0.02240553]\n",
      "Are they equal? False\n"
     ]
    }
   ],
   "source": [
    "# Verify weights\n",
    "saved_weight = np.loadtxt('./new-weights-sst2/layer0_intermediate_weight1.txt')\n",
    "model_weight = model.bert.encoder.layer[0].intermediate.dense.weight.detach().numpy().flatten()[:len(saved_weight)]\n",
    "\n",
    "print(\"Saved weight (first 5):\", saved_weight[:5])\n",
    "print(\"Model weight (first 5):\", model_weight[:5])\n",
    "print(\"Are they equal?\", np.allclose(saved_weight, model_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384\n",
      "16384\n",
      "16384\n",
      "16384\n"
     ]
    }
   ],
   "source": [
    "print(len(layer0_intermediate_weight1))\n",
    "print(len(layer0_intermediate_weight2))\n",
    "print(len(layer0_intermediate_weight3))\n",
    "print(len(layer0_intermediate_weight4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2465175986289978\n",
      "-0.00038853593287058175\n",
      "-0.22945359349250793\n",
      "-0.11301503330469131\n",
      "0.15645954012870789\n"
     ]
    }
   ],
   "source": [
    "print(layer0_intermediate_weight1[16383])\n",
    "print(layer0_intermediate_weight2[0])\n",
    "print(layer0_intermediate_weight2[16383])\n",
    "print(layer0_intermediate_weight3[16383])\n",
    "print(layer0_intermediate_weight4[16383])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2465175986289978\n",
      "-0.00038853593287058175\n",
      "-0.22945359349250793\n",
      "-0.11301503330469131\n",
      "0.15645954012870789\n"
     ]
    }
   ],
   "source": [
    "print(layer0_intermediate_weight[16383])\n",
    "print(layer0_intermediate_weight[16384])\n",
    "print(layer0_intermediate_weight[32767])\n",
    "print(layer0_intermediate_weight[49151])\n",
    "print(layer0_intermediate_weight[65535])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
